<!DOCTYPE html>
<html lang="en" data-theme="dark">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DelightMate - Your AI Assistant</title>
    <link href="{{ url_for('static', filename='css/tailwind.css') }}" rel="stylesheet">
    <link href="{{ url_for('static', filename='css/cosmic.css') }}" rel="stylesheet">
    <script src="{{ url_for('static', filename='js/theme.js') }}"></script>
    <style>
        :root {
            --bg-color: #121212;
            --text-color: #ffffff;
            --accent-color: #50b3a2;
            --secondary-color: #3a8292;
            --font-family: 'Inter', sans-serif;
            --sidebar-width: 350px; /* Define sidebar width as a variable for consistency */
            --main-container-width: 100%; /* Default width */
            --main-container-transform: 0; /* Default transform */
        }
        
        /* Light Mode Variables */
        [data-theme="light"] {
            --bg-color: #f5f5f5;
            --text-color: #121212;
        }
        
        body, html {
            margin: 0;
            padding: 0;
            height: 100%;
            overflow: hidden;
            font-family: 'Arial', sans-serif;
        }
        
        .cosmos-container {
            position: relative;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            min-height: 100vh;
            width: var(--main-container-width);
            transition: all 0.3s ease;
            transform: translateX(var(--main-container-transform));
            overflow-x: hidden; /* Prevent horizontal scrolling */
        }
        
        /* Chat container for messages */
        .conversation-container {
            display: flex;
            flex-direction: column;
            position: absolute;
            top: 55%; /* Position to appear between cosmic sphere and buttons */
            left: 50%;
            transform: translate(-50%, -50%);
            width: 80%;
            max-width: 500px; /* Reduced max-width for smaller chat window */
            background-color: rgba(0, 0, 0, 0.4);
            border-radius: 12px;
            padding: 10px;
            color: var(--text-color);
            backdrop-filter: blur(10px);
            max-height: 200px; /* Reduced max-height */
            overflow-y: auto;
            z-index: 5;
        }
        
        /* Message styling */
        .message {
            margin-bottom: 10px;
            display: flex;
            flex-direction: column;
            max-width: 80%;
        }
        
        .message.user {
            align-self: flex-end;
            text-align: right;
        }
        
        .message.ai {
            align-self: flex-start;
            text-align: left;
        }
        
        .message-content {
            padding: 8px 12px;
            border-radius: 12px;
            word-wrap: break-word;
        }
        
        .message.user .message-content {
            background-color: var(--accent-color);
            color: white;
            border-radius: 12px 12px 0 12px;
        }
        
        .message.ai .message-content {
            background-color: rgba(255, 255, 255, 0.1);
            color: var(--text-color);
            border-radius: 12px 12px 12px 0;
        }
        
        /* Enhanced close button styles */
        #closeTool:hover {
            background: rgba(255, 255, 255, 0.2) !important;
            transform: scale(1.1);
        }
        
        /* Panel shadow effects */
        .main-interface-panel {
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
        }
        
        .tool-interface-panel {
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
        }
        
        /* Responsive design for new layout */
        @media (max-width: 768px) {
            .cosmos-container {
                flex-direction: column !important;
                gap: 20px !important;
                padding: 20px !important;
            }
            
            .tool-interface-panel {
                min-height: auto !important;
            }
        }
    </style>
</head>
<body style="background-color: var(--bg-color);">
    <div class="app-wrapper" style="display: flex; height: 100vh; width: 100vw; overflow: hidden; position: relative;">
        <!-- Main Content Area - Takes Full Screen -->
        <div class="main-interface-panel" style="flex: 1; background: var(--bg-color); display: flex; flex-direction: column; align-items: center; justify-content: center; min-height: 100vh; position: relative; transition: all 0.4s cubic-bezier(0.4, 0, 0.2, 1); margin: 20px;">
            {% include 'components/navbar.html' %}
            
            <!-- User Profile -->
            {% if user and user.is_logged_in %}
            <div class="cosmic-user-profile" style="position: absolute; top: 20px; right: 20px;">
                {% if user.picture %}
                <img src="{{ user.picture }}" alt="Profile" style="width: 40px; height: 40px; border-radius: 50%;">
                {% else %}
                <div style="width: 40px; height: 40px; border-radius: 50%; background-color: rgba(64, 190, 255, 0.8); display: flex; justify-content: center; align-items: center; color: white; font-weight: bold;">
                    {{ user.name[0] if user.name else 'U' }}
                </div>
                {% endif %}
                <span class="cosmic-user-name" style="margin-left: 8px; color: var(--text-color);">{{ user.name if user.name else 'User' }}</span>
            </div>
            {% endif %}

            <!-- Cosmic Sphere with adjusted positioning -->
            <div class="cosmos-sphere" id="cosmosSphere" style="margin: 0;"></div>
            
            <!-- Status Text - positioned higher -->
            <div class="status-text" id="statusText" style="margin-top: 40px; font-size: 18px; color: var(--accent-color); text-align: center;">Ready to start...</div>
            
            <!-- Control Buttons -->
            <div class="controls" style="margin-top: 40px;">
                <button class="control-btn">
                    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                        <path d="M22 16.92v3a2 2 0 0 1-2.18 2 19.79 19.79 0 0 1-8.63-3.07 19.5 19.5 0 0 1-6-6 19.79 19.79 0 0 1-3.07-8.67A2 2 0 0 1 4.11 2h3a2 2 0 0 1 2 1.72 12.84 12.84 0 0 0 .7 2.81 2 2 0 0 1-.45 2.11L8.09 9.91a16 16 0 0 0 6 6l1.27-1.27a2 2 0 0 1 2.11-.45 12.84 12.84 0 0 0 2.81.7A2 2 0 0 1 22 16.92z"></path>
                    </svg>
                </button>
                <button class="control-btn microphone-btn" id="micButton">
                    <svg xmlns="http://www.w3.org/2000/svg" width="28" height="28" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                        <path d="M12 1a3 3 0 0 0-3 3v8a3 3 0 0 0 6 0V4a3 3 0 0 0-3-3z"></path>
                        <path d="M19 10v2a7 7 0 0 1-14 0v-2"></path>
                        <line x1="12" y1="19" x2="12" y2="23"></line>
                        <line x1="8" y1="23" x2="16" y2="23"></line>
                    </svg>
                </button>
                <button class="control-btn">
                    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                        <circle cx="11" cy="11" r="8"></circle>
                        <line x1="21" y1="21" x2="16.65" y2="16.65"></line>
                    </svg>
                </button>
            </div>
        </div>
        
        <!-- Tool Sidebar - Hidden by Default, Slides in from Right Side by Side -->
        <div id="toolSidebar" style="width: 0; opacity: 0; overflow: hidden; transition: all 0.4s cubic-bezier(0.4, 0, 0.2, 1); background: var(--bg-color); border-radius: 24px; border: 1px solid rgba(255, 255, 255, 0.1); backdrop-filter: blur(20px); margin: 20px 20px 20px 0; box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1); flex-shrink: 0;">
            <div class="tool-header" style="display: flex; justify-content: space-between; align-items: center; padding: 30px 30px 20px 30px; border-bottom: 1px solid rgba(255, 255, 255, 0.1);">
                <h3 id="toolTitle" style="margin: 0; color: var(--text-color); font-size: 1.4rem; font-weight: 600; white-space: nowrap;">Tool Title</h3>
                <button id="closeTool" style="background: rgba(255, 255, 255, 0.1); border: none; color: var(--text-color); font-size: 18px; cursor: pointer; width: 36px; height: 36px; border-radius: 50%; display: flex; align-items: center; justify-content: center; transition: all 0.2s ease;">×</button>
            </div>
            <div id="toolContent" class="tool-content" style="padding: 30px; height: calc(100vh - 160px); overflow-y: auto;">
                <!-- Tool content will be dynamically generated -->
            </div>
        </div>
    </div>

    <!-- JavaScript for Cosmic Visualization and Audio Recording -->
    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const cosmosSphere = document.getElementById('cosmosSphere');
            const statusText = document.getElementById('statusText');
            const micButton = document.getElementById('micButton');
            
            // Create a dedicated state management object to centralize our application state
            // This will help us keep track of state across different function calls
            const AppState = {
                // Recording state
                isRecording: false,
                isProcessing: false,
                pauseDetected: false,
                silenceStart: null,
                hasDetectedAudio: false,
                significantSpeechDetected: false,

                // Audio resources
                mediaRecorder: null,
                audioChunks: [],
                audioBlob: null,
                audioContext: null,
                analyser: null,
                source: null,

                // Timers and tracking
                continuousRecordingTimer: null,
                lastProcessedTime: 0,

                // Conversation state
                conversationActive: false,

                // Tool state
                activeTool: null, // Current active tool
                pendingToolAction: null, // Action waiting for confirmation

                // Debug
                logPrefix: '🎙️ VoiceAssistant:',

                // Methods for state management
                startConversation() {
                    this.conversationActive = true;
                    console.log(`${this.logPrefix} Conversation started`);
                },

                endConversation() {
                    this.conversationActive = false;
                    this.resetAudioState();
                    console.log(`${this.logPrefix} Conversation ended`);
                },

                resetAudioState() {
                    this.isRecording = false;
                    this.isProcessing = false;
                    this.pauseDetected = false;
                    this.silenceStart = null;
                    this.hasDetectedAudio = false;
                    this.significantSpeechDetected = false;
                    this.audioChunks = [];
                    console.log(`${this.logPrefix} Audio state reset`);
                },

                activateTool(toolName) {
                    this.activeTool = toolName;
                    console.log(`${this.logPrefix} Tool activated: ${toolName}`);
                },

                deactivateTool() {
                    this.activeTool = null;
                    this.pendingToolAction = null;
                    console.log(`${this.logPrefix} Tool deactivated`);
                },

                debug() {
                    console.log(`${this.logPrefix} State: 
                        Recording: ${this.isRecording},
                        Processing: ${this.isProcessing}, 
                        Conversation: ${this.conversationActive},
                        ActiveTool: ${this.activeTool}
                    `);
                }
            };

            // Audio processing variables - using AppState now for most of these
            let volumeData = [];
            let pauseTimeout = null;

            // Settings with default values
            let settings = {
                silenceThreshold: 15,
                pauseThreshold: 2.0, // Silence pause threshold in seconds
                echoCancel: true,
                noiseSuppress: true,
                continuousMode: true,
                minAudioSize: 10000, // Minimum audio size to consider as valid speech (bytes)
                significantAudioThreshold: 25 // Threshold for significant audio (higher than silence threshold)
            };

            // Create cosmic particles
            createCosmicParticles();
            
            // Microphone button click handler
            micButton.addEventListener('click', function() {
                console.log(`${AppState.logPrefix} Mic button clicked`);
                
                if (AppState.isRecording || AppState.conversationActive) {
                    endConversation();
                    // Change microphone icon to original icon when stopping
                    micButton.innerHTML = `
                        <svg xmlns="http://www.w3.org/2000/svg" width="28" height="28" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                            <path d="M12 1a3 3 0 0 0-3 3v8a3 3 0 0 0 6 0V4a3 3 0 0 0-3-3z"></path>
                            <path d="M19 10v2a7 7 0 0 1-14 0v-2"></path>
                            <line x1="12" y1="19" x2="12" y2="23"></line>
                            <line x1="8" y1="23" x2="16" y2="23"></line>
                        </svg>
                    `;
                    micButton.classList.remove('recording');
                } else {
                    startConversation();
                    // Change microphone icon to stop icon when recording
                    micButton.innerHTML = `
                        <svg xmlns="http://www.w3.org/2000/svg" width="28" height="28" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                            <rect x="6" y="6" width="12" height="12" rx="2" ry="2"></rect>
                        </svg>
                    `;
                    micButton.classList.add('recording');
                }
            });

            // Start the conversation session
            function startConversation() {
                // Update state
                AppState.startConversation();

                // Initialize audio components
                initAudioContext();
                statusText.textContent = "Starting microphone...";

                // Begin recording
                startRecording();
            }

            // End the conversation session
            function endConversation() {
                console.log(`${AppState.logPrefix} Ending conversation`);

                // Stop current recording if active
                if (AppState.isRecording) {
                    stopRecording();
                }

                // Clear any pending timers
                if (pauseTimeout) {
                    clearTimeout(pauseTimeout);
                    pauseTimeout = null;
                }

                // Clear continuous recording timer
                if (AppState.continuousRecordingTimer) {
                    clearInterval(AppState.continuousRecordingTimer);
                    AppState.continuousRecordingTimer = null;
                }

                // Update application state
                AppState.endConversation();

                // Update UI
                statusText.textContent = "Ready to start...";
            }

            // Initialize AudioContext (for volume analysis)
            function initAudioContext() {
                try {
                    // Initialize or reset
                    if (AppState.audioContext) {
                        AppState.audioContext.close();
                    }

                    window.AudioContext = window.AudioContext || window.webkitAudioContext;
                    AppState.audioContext = new AudioContext();
                    AppState.analyser = AppState.audioContext.createAnalyser();
                    AppState.analyser.fftSize = 256;

                    console.log(`${AppState.logPrefix} Audio context initialized successfully`);
                } catch (e) {
                    console.error(`${AppState.logPrefix} AudioContext not supported or error initializing:`, e);
                    statusText.textContent = "Audio features not supported in your browser";
                }
            }

            // Start recording audio
            async function startRecording() {
                if (AppState.isRecording) {
                    console.log(`${AppState.logPrefix} Already recording, not starting again`);
                    return;
                }

                console.log(`${AppState.logPrefix} Starting recording...`);
                AppState.debug();

                // Reset state variables
                AppState.isRecording = true;
                AppState.pauseDetected = false;
                AppState.silenceStart = null;
                AppState.hasDetectedAudio = false;
                AppState.significantSpeechDetected = false;
                AppState.audioChunks = [];

                try {
                    // Make sure audio context is initialized
                    if (!AppState.audioContext || !AppState.analyser) {
                        console.log(`${AppState.logPrefix} Re-initializing audio context`);
                        initAudioContext();
                    }

                    // Create constraints with echo cancellation and noise suppression
                    const constraints = {
                        audio: {
                            echoCancellation: settings.echoCancel,
                            noiseSuppression: settings.noiseSuppress,
                            autoGainControl: true
                        }
                    };

                    statusText.textContent = "Accessing microphone...";
                    const stream = await navigator.mediaDevices.getUserMedia(constraints);

                    // Start media recorder with higher bitrate for better quality
                    const options = { mimeType: 'audio/webm;codecs=opus', audioBitsPerSecond: 128000 };
                    AppState.mediaRecorder = new MediaRecorder(stream, options);

                    // Set up audio analysis for pause detection
                    if (AppState.audioContext && AppState.analyser) {
                        // Disconnect previous source if exists
                        if (AppState.source) {
                            AppState.source.disconnect();
                        }

                        AppState.source = AppState.audioContext.createMediaStreamSource(stream);
                        AppState.source.connect(AppState.analyser);

                        // Start monitoring volume
                        monitorVolume();
                        
                        // Start animation
                        startListening();
                    } else {
                        throw new Error("Audio context or analyser not initialized");
                    }

                    AppState.mediaRecorder.addEventListener('dataavailable', event => {
                        if (event.data.size > 0) {
                            AppState.audioChunks.push(event.data);
                        }
                    });

                    AppState.mediaRecorder.addEventListener('stop', () => {
                        console.log(`${AppState.logPrefix} MediaRecorder stopped, chunks: ${AppState.audioChunks.length}`);
                        if (AppState.audioChunks.length > 0) {
                            AppState.audioBlob = new Blob(AppState.audioChunks, { type: 'audio/webm;codecs=opus' });
                            console.log(`${AppState.logPrefix} Audio blob created, size: ${AppState.audioBlob.size}`);
                            if (!AppState.isProcessing) {
                                processAudio();
                            }
                        }
                    });

                    AppState.mediaRecorder.start(100); // Collect data in 100ms chunks
                    micButton.classList.add('recording');
                    statusText.textContent = "Listening...";

                    // Start continuous recording timer if enabled
                    if (settings.continuousMode) {
                        startContinuousRecordingTimer();
                    }

                } catch (error) {
                    console.error(`${AppState.logPrefix} Error starting recording:`, error);
                    statusText.textContent = "Error starting recording: " + error.message;

                    // Reset state on error
                    AppState.isRecording = false;
                }
            }

            // New function to handle continuous recording
            function startContinuousRecordingTimer() {
                // Clear any existing timer
                if (AppState.continuousRecordingTimer) {
                    clearInterval(AppState.continuousRecordingTimer);
                    AppState.continuousRecordingTimer = null;
                }

                console.log(`${AppState.logPrefix} Continuous listening mode active - will process on speech followed by silence`);
            }

            // Stop recording
            function stopRecording() {
                console.log(`${AppState.logPrefix} Stopping recording`);

                // Only stop if we have an active recorder
                if (AppState.mediaRecorder && AppState.mediaRecorder.state !== 'inactive') {
                    AppState.mediaRecorder.stop();
                    AppState.mediaRecorder.stream.getTracks().forEach(track => track.stop());
                }

                AppState.isRecording = false;
                AppState.conversationActive = false;
                micButton.classList.remove('recording');

                // Clear continuous recording timer
                if (AppState.continuousRecordingTimer) {
                    clearInterval(AppState.continuousRecordingTimer);
                    AppState.continuousRecordingTimer = null;
                }
            }

            // Monitor volume and detect silence
            function monitorVolume() {
                if (!AppState.analyser || !AppState.isRecording) {
                    console.log(`${AppState.logPrefix} Cannot monitor volume - analyser or recording state invalid`);
                    return;
                }

                const bufferLength = AppState.analyser.frequencyBinCount;
                const volumeData = new Uint8Array(bufferLength);
                AppState.analyser.getByteFrequencyData(volumeData);

                // Calculate average volume level
                let sum = 0;
                for (let i = 0; i < bufferLength; i++) {
                    sum += volumeData[i];
                }
                const avg = sum / bufferLength;

                // Check if we've detected significant speech (using a higher threshold)
                if (avg > settings.significantAudioThreshold) {
                    if (!AppState.significantSpeechDetected) {
                        console.log(`${AppState.logPrefix} Speech detected - volume level: ${avg.toFixed(1)}`);
                    }
                    AppState.significantSpeechDetected = true;
                    // Reset silence start when speech is detected
                    AppState.silenceStart = null;

                    // Only log occasionally to reduce console spam
                    if (Math.random() < 0.02) {
                        console.log(`${AppState.logPrefix} Detected speech: ${avg.toFixed(2)}`);
                    }
                }

                // Regular audio detection for visualization
                if (avg > settings.silenceThreshold) {
                    AppState.hasDetectedAudio = true;
                }

                // Silence detection logic - only trigger processing if we had significant speech followed by silence
                if (AppState.significantSpeechDetected) {
                    if (avg < settings.silenceThreshold) {
                        // Start silence timer if not already started
                        if (!AppState.silenceStart) {
                            AppState.silenceStart = Date.now();
                            console.log(`${AppState.logPrefix} Silence started after speech`);
                        }

                        // Check if silence has lasted long enough to be a pause
                        const silenceDuration = (Date.now() - AppState.silenceStart) / 1000;

                        // Update debug status more frequently during silence
                        if (Math.random() < 0.1) {
                            console.log(`${AppState.logPrefix} Silence duration: ${silenceDuration.toFixed(1)}s`);
                        }

                        // Only process when:
                        // 1. We've detected significant speech
                        // 2. Followed by silence for the pause threshold duration
                        // 3. We're not already processing
                        // 4. Enough time has passed since last processing
                        if (silenceDuration > settings.pauseThreshold && !AppState.pauseDetected && !AppState.isProcessing &&
                            (Date.now() - AppState.lastProcessedTime > 3000)) {

                            console.log(`${AppState.logPrefix} Processing after ${silenceDuration.toFixed(1)}s of silence following speech`);
                            AppState.pauseDetected = true;
                            pauseAndProcess();
                        }
                    } else {
                        // Reset silence timer if sound detected
                        if (AppState.silenceStart) {
                            console.log(`${AppState.logPrefix} Silence interrupted - continuing to listen`);
                        }
                        AppState.silenceStart = null;
                    }
                }

                // Continue monitoring as long as we're recording
                if (AppState.isRecording) {
                    requestAnimationFrame(monitorVolume);
                } else {
                    console.log(`${AppState.logPrefix} Volume monitoring stopped - recording ended`);
                }
            }

            // Pause recording and process current audio
            function pauseAndProcess() {
                console.log(`${AppState.logPrefix} Pausing to process audio`);

                if (!AppState.isRecording || AppState.isProcessing) {
                    console.log(`${AppState.logPrefix} Cannot pause - not recording or already processing`);
                    return;
                }

                // Stop the current recorder to get the data
                const currentMediaRecorder = AppState.mediaRecorder;
                currentMediaRecorder.stop();

                statusText.textContent = "Processing your message...";

                // Update state
                AppState.isRecording = false;

                // Store the callback on the window object so it can be accessed from anywhere
                window.resumeRecordingCallback = resumeRecording;
            }

            // resumeRecording function - improved to fix visualization and silence detection
            const resumeRecording = async () => {
                console.log(`${AppState.logPrefix} Resuming recording callback triggered`);
                console.log(`${AppState.logPrefix} Conversation active: ${AppState.conversationActive}`);

                // Important: Use AppState.conversationActive to determine if we should resume
                if (AppState.conversationActive) {
                    console.log(`${AppState.logPrefix} Resuming recording - conversation is active`);

                    try {
                        // Reset AppState for a fresh start with the new recording session
                        AppState.isRecording = false;
                        AppState.isProcessing = false;
                        AppState.significantSpeechDetected = false;
                        AppState.pauseDetected = false;
                        AppState.silenceStart = null;
                        AppState.audioChunks = [];

                        // CRITICAL FIX: Instead of trying to reuse the old stream,
                        // request a fresh microphone stream each time
                        const constraints = {
                            audio: {
                                echoCancellation: settings.echoCancel,
                                noiseSuppression: settings.noiseSuppress,
                                autoGainControl: true
                            }
                        };

                        console.log(`${AppState.logPrefix} Requesting fresh microphone stream`);
                        const stream = await navigator.mediaDevices.getUserMedia(constraints);

                        // Reinitialize the audio context if needed
                        if (!AppState.audioContext || !AppState.analyser) {
                            console.log(`${AppState.logPrefix} Reinitializing audio context`);
                            initAudioContext();
                        }

                        // Start a new recorder with the fresh stream
                        const options = { mimeType: 'audio/webm;codecs=opus', audioBitsPerSecond: 128000 };
                        AppState.mediaRecorder = new MediaRecorder(stream, options);

                        // Set up event handlers again
                        AppState.mediaRecorder.addEventListener('dataavailable', event => {
                            if (event.data.size > 0) {
                                AppState.audioChunks.push(event.data);
                            }
                        });

                        AppState.mediaRecorder.addEventListener('stop', () => {
                            if (AppState.audioChunks.length > 0) {
                                AppState.audioBlob = new Blob(AppState.audioChunks, { type: 'audio/webm;codecs=opus' });
                                if (!AppState.isProcessing) {
                                    processAudio();
                                }
                            }
                        });

                        // Set up audio analysis again with the fresh stream
                        if (AppState.audioContext && AppState.analyser) {
                            // Disconnect previous source if exists
                            if (AppState.source) {
                                AppState.source.disconnect();
                            }

                            AppState.source = AppState.audioContext.createMediaStreamSource(stream);
                            AppState.source.connect(AppState.analyser);

                            // Start recording first, then visualization
                            AppState.mediaRecorder.start(100);
                            AppState.isRecording = true;

                            // Start monitoring volume with the fresh stream
                            // Using setTimeout to ensure the recorder is fully started
                            setTimeout(() => {
                                console.log(`${AppState.logPrefix} Starting volume monitoring`);
                                monitorVolume();
                            }, 100);
                        } else {
                            throw new Error("Audio context or analyser not properly initialized");
                        }

                        micButton.classList.add('recording');
                        statusText.textContent = "Listening...";

                        console.log(`${AppState.logPrefix} Successfully restarted recording with fresh stream`);

                        // Debug state
                        AppState.debug();

                    } catch (error) {
                        console.error(`${AppState.logPrefix} Error resuming recording:`, error);
                        statusText.textContent = "Error resuming: " + error.message;

                        // Try to fully restart recording as fallback
                        console.log(`${AppState.logPrefix} Falling back to complete restart`);
                        setTimeout(startRecording, 1000);
                    }
                } else {
                    console.log(`${AppState.logPrefix} Not resuming recording - conversation has ended`);
                }
            };

            // Process recorded audio - UPDATED VERSION
            async function processAudio() {
                if (!AppState.audioBlob || AppState.audioBlob.size === 0 || AppState.isProcessing) {
                    console.log(`${AppState.logPrefix} Cannot process audio - no blob, empty blob, or already processing`);
                    return;
                }

                AppState.isProcessing = true;
                AppState.lastProcessedTime = Date.now();
                console.log(`${AppState.logPrefix} Processing audio blob of size: ${AppState.audioBlob.size} bytes`);

                // Skip processing if the audio is too small to contain meaningful speech
                if (AppState.audioBlob.size < settings.minAudioSize) {
                    console.log(`${AppState.logPrefix} Audio too small to contain speech, skipping processing`);
                    AppState.isProcessing = false;

                    resumeRecordingAfterProcessing();
                    return;
                }

                // Create FormData with the audio blob
                const formData = new FormData();
                formData.append('audio', AppState.audioBlob);

                try {
                    // Step 1: Speech to Text
                    statusText.textContent = "Converting speech to text...";
                    console.log(`${AppState.logPrefix} Sending audio to STT API`);

                    const sttResponse = await fetch('/api/stt', {
                        method: 'POST',
                        body: formData,
                        // Add timeout to prevent hanging requests
                        signal: AbortSignal.timeout(10000) // 10 second timeout
                    });

                    if (!sttResponse.ok) {
                        throw new Error(`STT server error: ${sttResponse.status} - ${await sttResponse.text()}`);
                    }

                    const sttData = await sttResponse.json();
                    if (!sttData.success) {
                        throw new Error(sttData.error || 'Failed to transcribe audio');
                    }

                    const transcript = sttData.transcript;
                    console.log(`${AppState.logPrefix} Received transcript: "${transcript}"`);

                    if (!transcript || transcript.trim() === '') {
                        // Silently resume recording without any messages about no speech
                        console.log(`${AppState.logPrefix} No speech detected in transcription`);
                        AppState.isProcessing = false;
                        resumeRecordingAfterProcessing();
                        return;
                    }

                    // Skip if transcript contains only filler words
                    const fillerWords = ['um', 'uh', 'mmm', 'hmm', 'ah', 'er'];
                    const cleanTranscript = transcript.toLowerCase().trim();
                    if (fillerWords.some(word => cleanTranscript === word)) {
                        console.log(`${AppState.logPrefix} Skipping filler: "${cleanTranscript}"`);
                        AppState.isProcessing = false;
                        resumeRecordingAfterProcessing();
                        return;
                    }

                    // Check for pending tool confirmations first
                    if (AppState.pendingToolAction) {
                        try {
                            const wasConfirmation = await processToolConfirmation(transcript);
                            if (wasConfirmation) {
                                // If it was a confirmation, we don't need to process further
                                AppState.isProcessing = false;
                                resumeRecordingAfterProcessing();
                                return;
                            }
                        } catch (error) {
                            console.error(`${AppState.logPrefix} Error processing tool confirmation:`, error);
                        }
                    }

                    // Step 2: Send to Agent with proper system prompt about capabilities
                    statusText.textContent = "Getting AI response...";
                    console.log(`${AppState.logPrefix} Sending transcript to Agent API with capabilities context`);

                    // Create a detailed system prompt that explains the assistant's capabilities
                    const systemPrompt = `You are DelightMate, a powerful voice assistant with these capabilities:

✅ Writing and sending emails
✅ Summarizing emails 
✅ Checking calendar availability
✅ Adding events to calendars
✅ Voice conversations

CAPABILITIES GUIDE:
1. When a user asks you to send an email, respond enthusiastically like "Of course! I'll help you draft that email." NEVER say you can't send emails.
2. When a user asks about their calendar, respond positively like "Let me check your calendar for you." NEVER say you can't access calendars.
3. Keep responses concise and conversational.

INTENT DETECTION:
When you identify a user intent related to a specific tool, include it in your response in this format:
- For email composition: {"tool": "email", "action": "compose", "params": {"recipient": "NAME", "subject": "SUBJECT"}}
- For email summary: {"tool": "email", "action": "summarize", "params": {"count": NUMBER}}
- For calendar checking: {"tool": "calendar", "action": "check", "params": {"date": "DATE"}}
- For calendar event creation: {"tool": "calendar", "action": "add", "params": {"title": "TITLE", "date": "DATE", "time": "TIME"}}
If no specific tool intent is detected, return null for the intent.

RESPONSE FORMAT:
- For regular questions: Provide a helpful, brief response.
- For email requests: Respond with "I'll help you write that email" or similar and assume you can do it.
- For calendar requests: Respond with "I'll check your calendar" or similar and assume you can do it.
- NEVER say you're an AI that can't perform these tasks - you are a voice assistant with these capabilities.

Your response should include both a conversational text reply AND the detected intent object.

The system will handle the actual implementation of these capabilities.`;

                    // Include the transcript and system prompt in the request to OpenAI
                    const agentRequestBody = {
                        transcript: transcript,
                        system_prompt: systemPrompt
                    };

                    // Send request to the agent API
                    const agentResponse = await fetch('/api/agent', {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json'
                        },
                        body: JSON.stringify(agentRequestBody),
                        // Add timeout to prevent hanging requests
                        signal: AbortSignal.timeout(30000) // 30 second timeout
                    });

                    if (!agentResponse.ok) {
                        throw new Error(`Agent server error: ${agentResponse.status}`);
                    }

                    const agentData = await agentResponse.json();
                    if (!agentData.success) {
                        throw new Error(agentData.error || 'Failed to process with agent');
                    }

                    console.log(`${AppState.logPrefix} Received agent response:`, agentData);

                    // Extract text response and detected intent from the agent response
                    const responseText = agentData.response;
                    const detectedIntent = agentData.intent;

                    // Convert to speech using TTS API
                    await processAIResponseTTS(responseText);

                    // After the AI response and TTS, handle the detected tool intent if any
                    if (detectedIntent) {
                        try {
                            console.log(`${AppState.logPrefix} Processing detected intent from AI:`, detectedIntent);
                            AppState.isProcessingTool = true;
                            await handleToolIntent(detectedIntent, transcript);
                            AppState.isProcessingTool = false;
                        } catch (error) {
                            console.error(`${AppState.logPrefix} Error handling tool:`, error);
                            console.log(`${AppState.logPrefix} Tool error: ${error.message}`);
                            return true; // Return true to prevent normal conversation flow
                        }
                    }

                    // Resume recording after processing is complete
                    resumeRecordingAfterProcessing();

                } catch (error) {
                    console.error(`${AppState.logPrefix} Error:`, error);
                    statusText.textContent = 'Error: ' + error.message;

                    // Resume listening after error
                    setTimeout(() => {
                        resumeRecordingAfterProcessing();
                    }, 2000);
                } finally {
                    AppState.isProcessing = false;
                    AppState.pauseDetected = false;
                }
            }

            // Helper function to resume recording after processing
            function resumeRecordingAfterProcessing() {
                if (window.resumeRecordingCallback) {
                    console.log(`${AppState.logPrefix} Calling resume callback after processing`);
                    const callback = window.resumeRecordingCallback;
                    window.resumeRecordingCallback = null;
                    callback();
                } else {
                    // Fallback if callback is missing - restart recording directly
                    console.log(`${AppState.logPrefix} No callback found - using fallback restart`);
                    if (AppState.conversationActive) {
                        setTimeout(startRecording, 500);
                    }
                }
            }

            // Helper function specifically for TTS without conversation log (already added by processAIResponse)
            async function processAIResponseTTS(message) {
                try {
                    statusText.textContent = "Converting response to speech...";
                    console.log(`${AppState.logPrefix} Sending response to TTS API`);

                    const ttsResponse = await fetch('/api/tts', {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json'
                        },
                        body: JSON.stringify({ text: message }),
                        // Add timeout to prevent hanging requests
                        signal: AbortSignal.timeout(15000) // 15 second timeout
                    });

                    if (!ttsResponse.ok) {
                        throw new Error(`TTS server error: ${ttsResponse.status}`);
                    }

                    console.log(`${AppState.logPrefix} Received TTS audio response`);

                    // Play the audio response
                    const audioBlob = await ttsResponse.blob();
                    const audioUrl = URL.createObjectURL(audioBlob);
                    const audioPlayer = new Audio(audioUrl);

                    // Create a Promise that resolves when audio playback completes
                    return new Promise((resolve, reject) => {
                        const onEnded = () => {
                            console.log(`${AppState.logPrefix} Audio playback ended, resuming listening`);
                            audioPlayer.removeEventListener('ended', onEnded);
                            audioPlayer.removeEventListener('error', onError);
                            resolve(true);
                        };

                        const onError = (error) => {
                            console.error(`${AppState.logPrefix} Audio playback error:`, error);
                            audioPlayer.removeEventListener('ended', onEnded);
                            audioPlayer.removeEventListener('error', onError);
                            reject(error);
                        };

                        // Set up event listeners
                        audioPlayer.addEventListener('ended', onEnded);
                        audioPlayer.addEventListener('error', onError);

                        statusText.textContent = "Playing response...";

                        // Start playback
                        audioPlayer.play().catch(error => {
                            console.error(`${AppState.logPrefix} Error starting audio playback:`, error);
                            onError(error);
                        });
                    });
                } catch (error) {
                    console.error(`${AppState.logPrefix} Error during TTS:`, error);
                    return false;
                }
            }

            // Tool detection system - analyzes transcript to identify tool intents
            function detectToolIntent(transcript) {
                const text = transcript.toLowerCase();
                console.log(`${AppState.logPrefix} Analyzing intent for: "${text}"`);

                // Email writing/sending detection
                if (text.includes("write an email") ||
                    text.includes("send an email") ||
                    text.includes("compose an email") ||
                    ((text.includes("email") || text.includes("mail")) &&
                        (text.includes("to ") || text.includes("write") || text.includes("send") || text.includes("compose")))) {

                    // Try to extract recipient
                    let recipient = "recipient";
                    let subject = "Meeting Follow-up";

                    console.log(`${AppState.logPrefix} Detected email intent with recipient: ${recipient}, subject: ${subject}`);

                    return {
                        tool: "email",
                        action: "compose",
                        params: { recipient, subject }
                    };
                }

                // Email summary detection
                if ((text.includes("summarize") || text.includes("summary") || text.includes("check")) &&
                    (text.includes("email") || text.includes("inbox") || text.includes("messages"))) {

                    // Try to extract count
                    let count = 3; // Default

                    console.log(`${AppState.logPrefix} Detected email summary intent for ${count} emails`);

                    return {
                        tool: "email",
                        action: "summarize",
                        params: { count }
                    };
                }

                // Calendar check detection
                if (text.includes("calendar") &&
                    (text.includes("check") || text.includes("look") || text.includes("view") ||
                        text.includes("availability") || text.includes("free") || text.includes("busy") ||
                        text.includes("schedule") || text.includes("appointments") ||
                        text.includes("when am i"))) {

                    // Try to extract date
                    let date = "today";

                    console.log(`${AppState.logPrefix} Detected calendar check intent for date: ${date}`);

                    return {
                        tool: "calendar",
                        action: "check",
                        params: { date }
                    };
                }

                // No tool intent detected
                console.log(`${AppState.logPrefix} No tool intent detected, treating as conversation`);
                return null;
            }

            // Handle tool activation based on detected intent
            async function handleToolIntent(toolIntent, transcript) {
                console.log(`${AppState.logPrefix} Handling tool intent:`, toolIntent);

                if (!toolIntent) return false;

                try {
                    switch (toolIntent.tool) {
                        case "email":
                            if (toolIntent.action === "compose") {
                                await handleEmailCompose(toolIntent.params, transcript);
                                return true;
                            } else if (toolIntent.action === "summarize") {
                                await handleEmailSummarize(toolIntent.params, transcript);
                                return true;
                            }
                            break;

                        case "calendar":
                            if (toolIntent.action === "check") {
                                await handleCalendarCheck(toolIntent.params, transcript);
                                return true;
                            } else if (toolIntent.action === "add") {
                                await handleCalendarAdd(toolIntent.params, transcript);
                                return true;
                            }
                            break;
                    }

                    return false;
                } catch (error) {
                    console.error(`${AppState.logPrefix} Error handling tool intent:`, error);
                    console.log(`${AppState.logPrefix} Tool error: ${error.message}`);
                    return true; // Return true to prevent normal conversation flow
                }
            }

            // Process user confirmation for pending actions
            async function processToolConfirmation(transcript) {
                if (!AppState.pendingToolAction) {
                    return false;
                }

                const affirmativeResponses = ['yes', 'yeah', 'sure', 'okay', 'ok', 'yep', 'correct', 'confirm', 'do it', 'please do', 'send it', 'that\'s right', 'sounds good', 'go ahead', 'definitely'];
                const negativeResponses = ['no', 'nope', 'cancel', 'don\'t', 'stop', 'wait', 'hold on', 'incorrect', 'that\'s wrong', 'nevermind', 'forget it', 'don\'t do that'];

                const cleanTranscript = transcript.toLowerCase().trim();

                // Check if the response is affirmative
                if (affirmativeResponses.some(response => cleanTranscript.includes(response))) {
                    console.log(`${AppState.logPrefix} Detected affirmative response: "${cleanTranscript}"`);
                    await executeToolAction(AppState.pendingToolAction, true);
                    AppState.pendingToolAction = null;
                    return true;
                }

                // Check if the response is negative
                if (negativeResponses.some(response => cleanTranscript.includes(response))) {
                    console.log(`${AppState.logPrefix} Detected negative response: "${cleanTranscript}"`);
                    hideTool();
                    AppState.pendingToolAction = null;
                    return true;
                }

                // If the response doesn't match confirmation patterns, return false
                return false;
            }

            // Execute the confirmed tool action
            async function executeToolAction(toolAction, isConfirmed) {
                if (!isConfirmed || !toolAction) {
                    return;
                }

                console.log(`${AppState.logPrefix} Executing tool action:`, toolAction);

                try {
                    switch (toolAction.tool) {
                        case "email":
                            if (toolAction.action === "send") {
                                // Brief status update only
                                statusText.textContent = "Sending email...";

                                // Simulate a brief waiting period
                                await new Promise(resolve => setTimeout(resolve, 1500));

                                // Concise confirmation
                                hideTool();

                                // Deactivate the tool
                                AppState.deactivateTool();
                            }
                            break;

                        case "calendar":
                            if (toolAction.action === "create") {
                                const title = toolAction.params.title;
                                const date = toolAction.params.date;

                                // Update the status text only (no TTS)
                                statusText.textContent = "Creating calendar event...";

                                // Simulate a brief waiting period
                                await new Promise(resolve => setTimeout(resolve, 1500));

                                // Concise confirmation with TTS
                                hideTool();

                                // Deactivate the tool
                                AppState.deactivateTool();
                            }
                            break;
                    }
                } catch (error) {
                    console.error(`${AppState.logPrefix} Error executing tool action:`, error);
                    hideTool();

                    // Make sure to deactivate the tool on error
                    AppState.deactivateTool();
                }
            }

            // Email Tool Handlers
            async function handleEmailCompose(params, transcript) {
                try {
                    console.log(`${AppState.logPrefix} Handling email compose tool`);
                    // Set the active tool
                    AppState.activateTool("email");
                    
                    // Determine recipient email format
                    let recipientName = params.recipient || "Recipient";
                    let recipientEmail = `${recipientName.toLowerCase().replace(/\s+/g, '.')}@example.com`;
                    
                    // Generate a basic email template
                    const emailContent = `
                        <div class="email-form" style="background: rgba(255, 255, 255, 0.03); padding: 30px; border-radius: 24px; border: 1px solid rgba(255, 255, 255, 0.1); backdrop-filter: blur(20px);">
                            <h4 style="margin: 0 0 24px 0; color: var(--accent-color); font-size: 1.2rem; font-weight: 600; text-align: center;">Compose New Email</h4>
                            <div class="email-field" style="margin-bottom: 20px;">
                                <label for="email-to" style="display: block; margin-bottom: 8px; font-weight: 500; color: var(--text-color); font-size: 14px;">To:</label>
                                <input type="text" id="email-to" value="${recipientEmail}" style="width: 100%; padding: 14px 16px; border: 1px solid rgba(255, 255, 255, 0.2); border-radius: 12px; font-family: inherit; font-size: 15px; background: rgba(255, 255, 255, 0.05); color: var(--text-color); transition: all 0.2s ease;">
                            </div>
                            <div class="email-field" style="margin-bottom: 20px;">
                                <label for="email-subject" style="display: block; margin-bottom: 8px; font-weight: 500; color: var(--text-color); font-size: 14px;">Subject:</label>
                                <input type="text" id="email-subject" value="${params.subject || 'Meeting Follow-up'}" style="width: 100%; padding: 14px 16px; border: 1px solid rgba(255, 255, 255, 0.2); border-radius: 12px; font-family: inherit; font-size: 15px; background: rgba(255, 255, 255, 0.05); color: var(--text-color); transition: all 0.2s ease;">
                            </div>
                            <div class="email-field" style="margin-bottom: 20px;">
                                <label for="email-body" style="display: block; margin-bottom: 8px; font-weight: 500; color: var(--text-color); font-size: 14px;">Message:</label>
                                <textarea id="email-body" style="width: 100%; padding: 14px 16px; border: 1px solid rgba(255, 255, 255, 0.2); border-radius: 12px; font-family: inherit; font-size: 15px; background: rgba(255, 255, 255, 0.05); color: var(--text-color); transition: all 0.2s ease; min-height: 120px; resize: vertical;">Hello ${recipientName},

I hope this email finds you well. I wanted to follow up on our recent conversation about the project.

Let me know if you have any questions.

Best regards,
[Your Name]</textarea>
                            </div>
                            <div class="tool-buttons" style="display: flex; justify-content: center; gap: 16px; margin-top: 30px;">
                                <button class="tool-button secondary" id="email-cancel" style="padding: 12px 28px; border-radius: 12px; font-weight: 500; cursor: pointer; transition: all 0.2s ease; min-width: 120px; margin: 0; font-size: 14px; background: rgba(255, 255, 255, 0.1); color: var(--text-color); border: 1px solid rgba(255, 255, 255, 0.2);">Cancel</button>
                                <button class="tool-button primary" id="email-send" style="padding: 12px 28px; border-radius: 12px; font-weight: 500; cursor: pointer; transition: all 0.2s ease; min-width: 120px; margin: 0; font-size: 14px; background: var(--accent-color); color: white; border: none; box-shadow: 0 4px 15px rgba(80, 179, 162, 0.3);">Send Email</button>
                            </div>
                        </div>
                    `;
                    
                    // Show the tool with the email content
                    showTool("Email");
                    document.getElementById('toolContent').innerHTML = emailContent;
                    
                    // Add event listeners
                    document.getElementById('email-send').addEventListener('click', async () => {
                        // Get updated values from the form
                        const to = document.getElementById('email-to').value;
                        const subject = document.getElementById('email-subject').value;
                        const body = document.getElementById('email-body').value;
                        
                        AppState.pendingToolAction = {
                            tool: "email",
                            action: "send",
                            params: { to, subject, body }
                        };
                        
                        // Brief confirmation request via TTS
                        await processAIResponseTTS(`Send email to ${to}?`);
                    });
                    
                    document.getElementById('email-cancel').addEventListener('click', async () => {
                        hideTool();
                        await processAIResponseTTS("Email draft canceled.");
                        // Deactivate the tool when canceled
                        AppState.deactivateTool();
                    });
                    
                } catch (error) {
                    console.error(`${AppState.logPrefix} Error in handleEmailCompose:`, error);
                    await processAIResponseTTS("Couldn't create email. Please try again.");
                    
                    // Make sure to hide the tool if there's an error
                    try {
                        hideTool();
                    } catch (e) {
                        console.error(`${AppState.logPrefix} Error hiding tool:`, e);
                    }
                    
                    // Deactivate the tool on error
                    AppState.deactivateTool();
                }
            }

            async function handleEmailSummarize(params, transcript) {
                try {
                    // Set the active tool
                    AppState.activateTool("email");
                    
                    // Number of emails to summarize
                    const count = params.count || 3;
                    
                    // Generate dummy email summaries
                    let emailContent = `
                        <div class="email-list" style="background: rgba(255, 255, 255, 0.03); padding: 30px; border-radius: 24px; border: 1px solid rgba(255, 255, 255, 0.1); backdrop-filter: blur(20px);">
                            <h4 style="margin: 0 0 24px 0; color: var(--accent-color); font-size: 1.2rem; font-weight: 600; text-align: center;">Recent Emails (${count})</h4>
                    `;
                    
                    // Sample email data
                    const sampleEmails = [
                        {
                            from: "john.doe@example.com",
                            subject: "Project Status Update",
                            date: "Today, 10:30 AM",
                            preview: "The latest project milestones have been completed ahead of schedule. We're now moving into the testing phase and need your feedback on the current implementation."
                        },
                        {
                            from: "marketing@company.com",
                            subject: "Marketing Campaign Results",
                            date: "Yesterday, 4:15 PM",
                            preview: "The Q3 marketing campaign exceeded expectations with a 22% increase in engagement. Key metrics attached in the report show significant growth in all target demographics."
                        },
                        {
                            from: "support@service.com",
                            subject: "Your Support Ticket #45678",
                            date: "Jan 15, 2:45 PM",
                            preview: "Your recent support request has been resolved. The technical team implemented the solution and would appreciate your feedback on the service provided."
                        }
                    ];
                    
                    // Add emails to the content
                    for (let i = 0; i < Math.min(count, sampleEmails.length); i++) {
                        const email = sampleEmails[i];
                        emailContent += `
                            <div class="email-item" style="background: rgba(255, 255, 255, 0.05); padding: 20px; border-radius: 12px; border: 1px solid rgba(255, 255, 255, 0.1); margin-bottom: 16px; transition: all 0.2s ease;">
                                <div class="email-item-header" style="display: flex; justify-content: space-between; margin-bottom: 12px; font-size: 13px; color: var(--accent-color); font-weight: 500;">
                                    <span>${email.from}</span>
                                    <span>${email.date}</span>
                                </div>
                                <div class="email-item-subject" style="font-weight: 600; margin-bottom: 8px; color: var(--text-color); font-size: 15px;">${email.subject}</div>
                                <div class="email-item-preview" style="color: rgba(255, 255, 255, 0.7); line-height: 1.5; font-size: 14px;">${email.preview}</div>
                            </div>
                        `;
                    }
                    
                    emailContent += `
                        <div class="tool-buttons" style="display: flex; justify-content: center; gap: 16px; margin-top: 30px;">
                            <button class="tool-button secondary" id="email-refresh" style="padding: 12px 28px; border-radius: 12px; font-weight: 500; cursor: pointer; transition: all 0.2s ease; min-width: 120px; margin: 0; font-size: 14px; background: rgba(255, 255, 255, 0.1); color: var(--text-color); border: 1px solid rgba(255, 255, 255, 0.2);">Refresh</button>
                            <button class="tool-button secondary" id="email-close" style="padding: 12px 28px; border-radius: 12px; font-weight: 500; cursor: pointer; transition: all 0.2s ease; min-width: 120px; margin: 0; font-size: 14px; background: rgba(255, 255, 255, 0.1); color: var(--text-color); border: 1px solid rgba(255, 255, 255, 0.2);">Close</button>
                        </div>
                    </div>`;
                    
                    // Show the tool with the email summaries
                    showTool("Email Summary");
                    document.getElementById('toolContent').innerHTML = emailContent;
                    
                    // Add event listener for close button
                    document.getElementById('email-close').addEventListener('click', () => {
                        hideTool();
                        // Deactivate the tool when closed
                        AppState.deactivateTool();
                    });
                    
                    // Add event listener for refresh button (placeholder)
                    document.getElementById('email-refresh').addEventListener('click', () => {
                        // This would typically refresh the email list
                        // For now, just acknowledge the click
                        console.log("Refreshing email list");
                    });
                    
                    // Brief verbal acknowledgment
                    await processAIResponseTTS(`Found ${count} recent emails.`);
                    
                } catch (error) {
                    console.error(`${AppState.logPrefix} Error in handleEmailSummarize:`, error);
                    await processAIResponseTTS("Couldn't retrieve your emails. Please try again.");
                    
                    // Make sure to hide the tool if there's an error
                    try {
                        hideTool();
                    } catch (e) {
                        console.error(`${AppState.logPrefix} Error hiding tool:`, e);
                    }
                    
                    // Deactivate the tool on error
                    AppState.deactivateTool();
                }
            }

            // Calendar Tool Handlers
            async function handleCalendarCheck(params, transcript) {
                try {
                    // Set the active tool
                    AppState.activateTool("calendar");

                    // Generate a basic calendar view
                    const date = params.date === "today" ? new Date() : new Date();
                    const month = date.toLocaleString('default', { month: 'long' });
                    const year = date.getFullYear();

                    const dateStr = params.date === "today" ? "Today" : params.date;

                    let calendarContent = `
                        <div class="calendar-view" style="background: rgba(255, 255, 255, 0.03); padding: 30px; border-radius: 24px; border: 1px solid rgba(255, 255, 255, 0.1); backdrop-filter: blur(20px);">
                            <div class="calendar-header" style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 24px; padding-bottom: 16px; border-bottom: 1px solid rgba(255, 255, 255, 0.1);">
                                <h4 style="color: var(--accent-color); font-weight: 600; margin: 0;">${month} ${year}</h4>
                            </div>
                            <div class="calendar-days">
                                <h5 style="color: var(--text-color); margin-bottom: 16px;">${dateStr}'s Schedule (${date.toLocaleDateString()})</h5>
                                <div class="calendar-event" style="background: rgba(255, 255, 255, 0.05); border-left: 4px solid var(--accent-color); padding: 16px; margin: 12px 0; border-radius: 8px; border: 1px solid rgba(255, 255, 255, 0.1); transition: all 0.2s ease;">
                                    <strong style="color: var(--text-color);">9:00 AM - 10:00 AM</strong>: <span style="color: rgba(255, 255, 255, 0.8);">Team Standup</span>
                                </div>
                                <div class="calendar-event" style="background: rgba(255, 255, 255, 0.05); border-left: 4px solid var(--accent-color); padding: 16px; margin: 12px 0; border-radius: 8px; border: 1px solid rgba(255, 255, 255, 0.1); transition: all 0.2s ease;">
                                    <strong style="color: var(--text-color);">1:00 PM - 2:30 PM</strong>: <span style="color: rgba(255, 255, 255, 0.8);">Project Planning</span>
                                </div>
                                <div class="calendar-event" style="background: rgba(255, 255, 255, 0.05); border-left: 4px solid var(--accent-color); padding: 16px; margin: 12px 0; border-radius: 8px; border: 1px solid rgba(255, 255, 255, 0.1); transition: all 0.2s ease;">
                                    <strong style="color: var(--text-color);">4:00 PM - 5:00 PM</strong>: <span style="color: rgba(255, 255, 255, 0.8);">Client Call</span>
                                </div>
                                
                                <h5 class="free-time-header" style="margin-top: 24px; margin-bottom: 12px; color: var(--accent-color); font-weight: 600; border-bottom: 1px solid rgba(255, 255, 255, 0.1); padding-bottom: 8px;">Free Time Available:</h5>
                                <div class="free-time-slot" style="background: rgba(80, 179, 162, 0.1); border-left: 4px solid var(--accent-color); padding: 12px 16px; margin: 8px 0; border-radius: 8px; border: 1px solid rgba(255, 255, 255, 0.1); font-weight: 500; color: var(--accent-color);">
                                    <span>10:00 AM - 1:00 PM</span>
                                </div>
                                <div class="free-time-slot" style="background: rgba(80, 179, 162, 0.1); border-left: 4px solid var(--accent-color); padding: 12px 16px; margin: 8px 0; border-radius: 8px; border: 1px solid rgba(255, 255, 255, 0.1); font-weight: 500; color: var(--accent-color);">
                                    <span>2:30 PM - 4:00 PM</span>
                                </div>
                                <div class="free-time-slot" style="background: rgba(80, 179, 162, 0.1); border-left: 4px solid var(--accent-color); padding: 12px 16px; margin: 8px 0; border-radius: 8px; border: 1px solid rgba(255, 255, 255, 0.1); font-weight: 500; color: var(--accent-color);">
                                    <span>After 5:00 PM</span>
                                </div>
                            </div>
                            <div class="tool-buttons" style="display: flex; justify-content: center; gap: 16px; margin-top: 30px;">
                                <button class="tool-button secondary" id="prev-day" style="padding: 12px 28px; border-radius: 12px; font-weight: 500; cursor: pointer; transition: all 0.2s ease; min-width: 120px; margin: 0; font-size: 14px; background: rgba(255, 255, 255, 0.1); color: var(--text-color); border: 1px solid rgba(255, 255, 255, 0.2);">Previous Day</button>
                                <button class="tool-button secondary" id="calendar-close" style="padding: 12px 28px; border-radius: 12px; font-weight: 500; cursor: pointer; transition: all 0.2s ease; min-width: 120px; margin: 0; font-size: 14px; background: rgba(255, 255, 255, 0.1); color: var(--text-color); border: 1px solid rgba(255, 255, 255, 0.2);">Close</button>
                                <button class="tool-button primary" id="next-day" style="padding: 12px 28px; border-radius: 12px; font-weight: 500; cursor: pointer; transition: all 0.2s ease; min-width: 120px; margin: 0; font-size: 14px; background: var(--accent-color); color: white; border: none; box-shadow: 0 4px 15px rgba(80, 179, 162, 0.3);">Next Day</button>
                            </div>
                        </div>
                    `;

                    // Show the tool with the calendar content
                    showTool("Calendar");
                    document.getElementById('toolContent').innerHTML = calendarContent;

                    // Add event listener for close button
                    document.getElementById('calendar-close').addEventListener('click', () => {
                        hideTool();
                        AppState.deactivateTool();
                    });

                    // Add event listeners for day navigation (placeholder functionality)
                    document.getElementById('prev-day').addEventListener('click', () => {
                        console.log("Viewing previous day");
                    });

                    document.getElementById('next-day').addEventListener('click', () => {
                        console.log("Viewing next day");
                    });

                    // Send a brief TTS response
                    await processAIResponseTTS(`Checking your calendar for ${params.date === "today" ? "today" : params.date}.`);

                } catch (error) {
                    console.error(`${AppState.logPrefix} Error in handleCalendarCheck:`, error);
                    await processAIResponseTTS("I couldn't access your calendar. Please try again.");

                    // Make sure to hide the tool if there's an error
                    try {
                        hideTool();
                    } catch (e) {
                        console.error(`${AppState.logPrefix} Error hiding tool:`, e);
                    }

                    // Deactivate the tool
                    AppState.deactivateTool();
                }
            }

            async function handleCalendarAdd(params, transcript) {
                try {
                    // Set the active tool
                    AppState.activateTool("calendar");

                    // Generate a form to add an event
                    const today = new Date().toISOString().split('T')[0];

                    let eventContent = `
                        <div class="calendar-add-form" style="background: rgba(255, 255, 255, 0.03); padding: 30px; border-radius: 24px; border: 1px solid rgba(255, 255, 255, 0.1); backdrop-filter: blur(20px);">
                            <h4 style="margin: 0 0 24px 0; color: var(--accent-color); font-size: 1.2rem; font-weight: 600; text-align: center;">Add New Calendar Event</h4>
                            <div class="calendar-form-fields">
                                <div class="email-field" style="margin-bottom: 20px;">
                                    <label for="event-title" style="display: block; margin-bottom: 8px; font-weight: 500; color: var(--text-color); font-size: 14px;">Event Title:</label>
                                    <input type="text" id="event-title" value="${params.title || 'New Meeting'}" style="width: 100%; padding: 14px 16px; border: 1px solid rgba(255, 255, 255, 0.2); border-radius: 12px; font-family: inherit; font-size: 15px; background: rgba(255, 255, 255, 0.05); color: var(--text-color); transition: all 0.2s ease;">
                                </div>
                                <div class="email-field" style="margin-bottom: 20px;">
                                    <label for="event-date" style="display: block; margin-bottom: 8px; font-weight: 500; color: var(--text-color); font-size: 14px;">Date:</label>
                                    <input type="date" id="event-date" value="${today}" style="width: 100%; padding: 14px 16px; border: 1px solid rgba(255, 255, 255, 0.2); border-radius: 12px; font-family: inherit; font-size: 15px; background: rgba(255, 255, 255, 0.05); color: var(--text-color); transition: all 0.2s ease;">
                                </div>
                                <div class="email-field" style="margin-bottom: 20px;">
                                    <label for="event-time" style="display: block; margin-bottom: 8px; font-weight: 500; color: var(--text-color); font-size: 14px;">Start Time:</label>
                                    <input type="time" id="event-time" value="${params.time || '10:00'}" style="width: 100%; padding: 14px 16px; border: 1px solid rgba(255, 255, 255, 0.2); border-radius: 12px; font-family: inherit; font-size: 15px; background: rgba(255, 255, 255, 0.05); color: var(--text-color); transition: all 0.2s ease;">
                                </div>
                                <div class="email-field" style="margin-bottom: 20px;">
                                    <label for="event-duration" style="display: block; margin-bottom: 8px; font-weight: 500; color: var(--text-color); font-size: 14px;">Duration:</label>
                                    <select id="event-duration" style="width: 100%; padding: 14px 16px; border: 1px solid rgba(255, 255, 255, 0.2); border-radius: 12px; font-family: inherit; font-size: 15px; background: rgba(255, 255, 255, 0.05); color: var(--text-color); transition: all 0.2s ease;">
                                        <option value="30">30 minutes</option>
                                        <option value="60" selected>1 hour</option>
                                        <option value="90">1.5 hours</option>
                                        <option value="120">2 hours</option>
                                    </select>
                                </div>
                            </div>
                            <div class="tool-buttons" style="display: flex; justify-content: center; gap: 16px; margin-top: 30px;">
                                <button class="tool-button secondary" id="event-cancel" style="padding: 12px 28px; border-radius: 12px; font-weight: 500; cursor: pointer; transition: all 0.2s ease; min-width: 120px; margin: 0; font-size: 14px; background: rgba(255, 255, 255, 0.1); color: var(--text-color); border: 1px solid rgba(255, 255, 255, 0.2);">Cancel</button>
                                <button class="tool-button primary" id="event-create" style="padding: 12px 28px; border-radius: 12px; font-weight: 500; cursor: pointer; transition: all 0.2s ease; min-width: 120px; margin: 0; font-size: 14px; background: var(--accent-color); color: white; border: none; box-shadow: 0 4px 15px rgba(80, 179, 162, 0.3);">Create Event</button>
                            </div>
                        </div>
                    `;

                    // Show the tool with the event form
                    showTool("Calendar Event");
                    document.getElementById('toolContent').innerHTML = eventContent;

                    // Add event listeners
                    document.getElementById('event-create').addEventListener('click', async () => {
                        // Get updated values from the form
                        const title = document.getElementById('event-title').value;
                        const date = document.getElementById('event-date').value;
                        const time = document.getElementById('event-time').value;
                        const dateObj = new Date(date);
                        const formattedDate = dateObj.toLocaleDateString();

                        AppState.pendingToolAction = {
                            tool: "calendar",
                            action: "create",
                            params: {
                                title,
                                date: formattedDate,
                                time
                            }
                        };

                        // This verbal prompt is brief and asks for confirmation
                        await processAIResponseTTS(`Create "${title}" on ${formattedDate}?`);
                    });

                    document.getElementById('event-cancel').addEventListener('click', async () => {
                        hideTool();
                        await processAIResponseTTS("Event creation canceled.");
                        // Make sure to deactivate the tool when canceling
                        AppState.deactivateTool();
                    });

                    // Brief TTS response to acknowledge the request
                    await processAIResponseTTS(`Creating a calendar event. Please review the details.`);

                } catch (error) {
                    console.error(`${AppState.logPrefix} Error in handleCalendarAdd:`, error);
                    await processAIResponseTTS("I couldn't create your calendar event. Please try again.");

                    // Make sure to hide the tool if there's an error
                    try {
                        hideTool();
                    } catch (e) {
                        console.error(`${AppState.logPrefix} Error hiding tool:`, e);
                    }

                    // Deactivate the tool
                    AppState.deactivateTool();
                }
            }

            // Tool UI functions
            function showTool(title) {
                const toolSidebar = document.getElementById('toolSidebar');
                const toolTitle = document.getElementById('toolTitle');
                const mainPanel = document.querySelector('.main-interface-panel');

                if (toolSidebar && toolTitle) {
                    toolTitle.textContent = title || 'Tool';
                    // Slide in from right with proper width and opacity
                    toolSidebar.style.width = '450px';
                    toolSidebar.style.opacity = '1';
                    
                    // Add border radius to main panel for beautiful separation
                    if (mainPanel) {
                        mainPanel.style.borderRadius = '24px';
                    }
                    
                    document.getElementById('toolContent').innerHTML = '';
                } else {
                    console.error(`${AppState.logPrefix} Tool UI elements not found`);
                }
            }

            function hideTool() {
                const toolSidebar = document.getElementById('toolSidebar');
                const mainPanel = document.querySelector('.main-interface-panel');

                if (toolSidebar) {
                    // Slide out to the right
                    toolSidebar.style.width = '0';
                    toolSidebar.style.opacity = '0';
                    
                    // Remove border radius from main panel when tool is hidden
                    if (mainPanel) {
                        mainPanel.style.borderRadius = '0';
                    }
                    
                    document.getElementById('toolContent').innerHTML = '';
                } else {
                    console.error(`${AppState.logPrefix} Tool UI element not found`);
                }
            }

            // Close tool button event listener
            document.getElementById('closeTool').addEventListener('click', () => {
                hideTool();
            });

            // Initialize on load
            AppState.isProcessingTool = false;
            console.log(`${AppState.logPrefix} Voice Assistant initialized on homepage`);

            // Create cosmic particles in the sphere
            function createCosmicParticles() {
                const colors = ['white', 'blue', 'cyan', 'purple', 'pink'];
                const totalParticles = 200;
                const sphereRadius = 180; // Radius of the cosmic sphere
                
                cosmosSphere.innerHTML = ''; // Clear existing particles
                
                for (let i = 0; i < totalParticles; i++) {
                    const particle = document.createElement('div');
                    particle.className = `particle ${colors[Math.floor(Math.random() * colors.length)]}`;
                    
                    // Random size between 2-6px
                    const size = Math.random() * 4 + 2;
                    particle.style.width = `${size}px`;
                    particle.style.height = `${size}px`;
                    
                    // Position randomly within the sphere (spherical coordinates)
                    const theta = Math.random() * Math.PI * 2; // Horizontal angle
                    const phi = Math.acos(2 * Math.random() - 1); // Vertical angle
                    const radius = Math.random() * sphereRadius; // Distance from center
                    
                    const x = radius * Math.sin(phi) * Math.cos(theta);
                    const y = radius * Math.sin(phi) * Math.sin(theta);
                    const z = radius * Math.cos(phi);
                    
                    // Calculate opacity based on distance from center (more transparency at edges)
                    const opacity = 0.1 + (1 - (radius / sphereRadius)) * 0.9;
                    
                    // Set animation delay as a CSS variable
                    const delay = Math.random() * 2;
                    particle.style.setProperty('--particle-delay', delay);
                    
                    // Apply styles
                    particle.style.left = `calc(50% + ${x}px)`;
                    particle.style.top = `calc(50% + ${y}px)`;
                    particle.style.opacity = opacity;
                    particle.style.transform = `translateZ(${z}px)`;
                    
                    // Add subtle movement animation
                    const animDuration = 20 + Math.random() * 80;
                    const animDelay = Math.random() * -animDuration;
                    
                    // Use multiple animations for more interesting movement
                    particle.style.animation = `
                        rotate ${animDuration}s linear ${animDelay}s infinite,
                        float ${10 + Math.random() * 10}s ease-in-out ${Math.random() * -10}s infinite
                    `;
                    
                    cosmosSphere.appendChild(particle);
                }
            }
            
            // Start listening animation
            function startListening() {
                document.body.classList.add('listening');
                statusText.classList.add('active');
                cosmosSphere.classList.add('pulsate');
                
                // Make particles bulge with microphone input (real-time audio will handle this)
                const particles = document.querySelectorAll('.particle');
                particles.forEach(particle => {
                    // Add random delay for each particle to create a wave effect
                    const randomDelay = Math.random() * 0.5;
                    particle.style.setProperty('--particle-delay', randomDelay);
                });

                // Setup visualization animation
                function animate() {
                    if (!AppState.isRecording) return;
                    
                    const bufferLength = AppState.analyser.frequencyBinCount;
                    const dataArray = new Uint8Array(bufferLength);
                    AppState.analyser.getByteFrequencyData(dataArray);
                    
                    // Calculate average volume
                    let sum = 0;
                    for (let i = 0; i < bufferLength; i++) {
                        sum += dataArray[i];
                    }
                    const average = sum / bufferLength;
                    
                    // Scale particles based on volume
                    const particles = document.querySelectorAll('.particle');
                    const scale = 1 + (average / 256) * 0.5; // Scale between 1 and 1.5
                    
                    // Make cosmos sphere pulsate based on audio level
                    const pulseScale = 1 + (average / 256) * 0.1; // Subtle pulse effect
                    cosmosSphere.style.transform = `scale(${pulseScale})`;
                    
                    particles.forEach(particle => {
                        particle.style.transform = `scale(${scale})`;
                    });
                    
                    requestAnimationFrame(animate);
                }
                
                animate();
            }
            
            // Stop listening animation
            function stopListening() {
                document.body.classList.remove('listening');
                statusText.classList.remove('active');
                cosmosSphere.classList.remove('pulsate');
                cosmosSphere.style.transform = '';
                
                // Reset particles
                const particles = document.querySelectorAll('.particle');
                particles.forEach(particle => {
                    particle.style.transform = '';
                });
            }
        });
    </script>

    <!-- Footer -->
    <footer class="py-4 text-center text-blue-800 mt-auto">
        <p class="text-sm">&copy; 2025 DelightMate - Your Intelligent Assistant</p>
    </footer>

</body>
</html>