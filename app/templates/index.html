<!DOCTYPE html>
<html lang="en" data-theme="dark">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DelightMate - Your AI Assistant</title>
    <link href="{{ url_for('static', filename='css/tailwind.css') }}" rel="stylesheet">
    <link href="{{ url_for('static', filename='css/cosmic.css') }}" rel="stylesheet">
    <script src="{{ url_for('static', filename='js/theme.js') }}"></script>
    <style>
        :root {
            --bg-color: #121212;
            --text-color: #ffffff;
            --accent-color: #50b3a2;
            --secondary-color: #3a8292;
            --font-family: 'Inter', sans-serif;
            --sidebar-width: 350px; /* Define sidebar width as a variable for consistency */
            --main-container-width: 100%; /* Default width */
            --main-container-transform: 0; /* Default transform */
        }
        
        /* Light Mode Variables */
        [data-theme="light"] {
            --bg-color: #f5f5f5;
            --text-color: #121212;
        }
        
        body, html {
            margin: 0;
            padding: 0;
            height: 100%;
            overflow: hidden;
            font-family: 'Arial', sans-serif;
        }
        
        .cosmos-container {
            position: relative;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            min-height: 100vh;
            width: var(--main-container-width);
            transition: all 0.3s ease;
            transform: translateX(var(--main-container-transform));
            overflow-x: hidden; /* Prevent horizontal scrolling */
        }
        
        /* Chat container for messages */
        .conversation-container {
            display: flex;
            flex-direction: column;
            position: absolute;
            top: 55%; /* Position to appear between cosmic sphere and buttons */
            left: 50%;
            transform: translate(-50%, -50%);
            width: 80%;
            max-width: 500px; /* Reduced max-width for smaller chat window */
            background-color: rgba(0, 0, 0, 0.4);
            border-radius: 12px;
            padding: 10px;
            color: var(--text-color);
            backdrop-filter: blur(10px);
            max-height: 200px; /* Reduced max-height */
            overflow-y: auto;
            z-index: 5;
        }
        
        /* Message styling */
        .message {
            margin-bottom: 10px;
            display: flex;
            flex-direction: column;
            max-width: 80%;
        }
        
        .message.user {
            align-self: flex-end;
            text-align: right;
        }
        
        .message.ai {
            align-self: flex-start;
            text-align: left;
        }
        
        .message-content {
            padding: 8px 12px;
            border-radius: 12px;
            word-wrap: break-word;
        }
        
        .message.user .message-content {
            background-color: var(--accent-color);
            color: white;
            border-radius: 12px 12px 0 12px;
        }
        
        .message.ai .message-content {
            background-color: rgba(255, 255, 255, 0.1);
            color: var(--text-color);
            border-radius: 12px 12px 12px 0;
        }
    </style>
</head>
<body style="background-color: var(--bg-color);">
    <div class="app-wrapper" style="display: flex; height: 100vh; width: 100vw; overflow: hidden;">
        <!-- Main Content Area -->
        <div class="cosmos-container" style="flex: 1; position: relative; overflow: hidden;">
        {% include 'components/navbar.html' %}
        
        <!-- User Profile -->
        {% if user and user.is_logged_in %}
        <div class="cosmic-user-profile">
            {% if user.picture %}
            <img src="{{ user.picture }}" alt="Profile">
            {% else %}
            <div style="width: 40px; height: 40px; border-radius: 50%; background-color: rgba(64, 190, 255, 0.8); display: flex; justify-content: center; align-items: center; color: white; font-weight: bold;">
                {{ user.name[0] if user.name else 'U' }}
            </div>
            {% endif %}
            <span class="cosmic-user-name">{{ user.name if user.name else 'User' }}</span>
        </div>
        {% endif %}
        
        <!-- Voice Mode Indicator -->
        <!-- <div class="voice-mode">Voice mode</div> -->
        
        <!-- Welcome Message -->
        <!-- <div class="cosmic-welcome" id="welcomeMessage">
            <h2>I'm DelightMate</h2>
            <p>Your digital teammate ready to help with emails, calendar, and more.</p>
            <p class="welcome-hint">Click the microphone to start speaking</p>
        </div> -->

        <!-- Cosmic Sphere with adjusted positioning -->
        <div class="cosmos-sphere" id="cosmosSphere" style="margin-top: -30px;"></div>
        
        <!-- Status Text - positioned higher -->
        <div class="status-text" id="statusText" style="position: absolute; top: 20%; left: 50%; transform: translateX(-50%); font-size: 18px; color: var(--accent-color); z-index: 10;">Listening...</div>
        
        <!-- Conversation Container -->
        <div class="conversation-container" id="messageContainer" style="display: none; position: absolute; top: 40%; left: 50%; transform: translateX(-50%); width: 80%; max-width: 450px; max-height: 40%; overflow-y: auto; z-index: 10; padding: 15px; border-radius: 12px; background-color: rgba(0, 0, 0, 0.2); backdrop-filter: blur(10px);">
            <!-- Close button for conversation -->
            <button id="closeConversation" style="position: absolute; top: 5px; right: 5px; background: none; border: none; color: white; font-size: 16px; cursor: pointer; z-index: 11;">×</button>
            <!-- Messages will be added here dynamically -->
            <div id="responseMessage" style="position: absolute; left: -9999px; visibility: hidden;"><!-- Hidden element for screen readers --></div>
        </div>
        
        <!-- Control Buttons -->
        <div class="controls">
            <button class="control-btn">
                <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                    <path d="M22 16.92v3a2 2 0 0 1-2.18 2 19.79 19.79 0 0 1-8.63-3.07 19.5 19.5 0 0 1-6-6 19.79 19.79 0 0 1-3.07-8.67A2 2 0 0 1 4.11 2h3a2 2 0 0 1 2 1.72 12.84 12.84 0 0 0 .7 2.81 2 2 0 0 1-.45 2.11L8.09 9.91a16 16 0 0 0 6 6l1.27-1.27a2 2 0 0 1 2.11-.45 12.84 12.84 0 0 0 2.81.7A2 2 0 0 1 22 16.92z"></path>
                </svg>
            </button>
            <button class="control-btn microphone-btn" id="micButton">
                <svg xmlns="http://www.w3.org/2000/svg" width="28" height="28" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                    <path d="M12 1a3 3 0 0 0-3 3v8a3 3 0 0 0 6 0V4a3 3 0 0 0-3-3z"></path>
                    <path d="M19 10v2a7 7 0 0 1-14 0v-2"></path>
                    <line x1="12" y1="19" x2="12" y2="23"></line>
                    <line x1="8" y1="23" x2="16" y2="23"></line>
                </svg>
            </button>
            <button class="control-btn">
                <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                    <circle cx="11" cy="11" r="8"></circle>
                    <line x1="21" y1="21" x2="16.65" y2="16.65"></line>
                </svg>
            </button>
        </div>

    </div>
        
        <!-- Right Sidebar for Tools - with visible border in both themes -->
        <div id="toolSidebar" class="tool-sidebar" style="width: 0; height: 100vh; background-color: var(--bg-color); border-left: 2px solid var(--text-color); transition: width 0.3s ease; overflow: hidden;">
            <div class="tool-header" style="display: flex; justify-content: space-between; align-items: center; padding: 15px; border-bottom: 1px solid rgba(255, 255, 255, 0.1);">
                <h3 id="toolTitle" style="margin: 0; color: var(--text-color); font-size: 1.2rem;">Tool Title</h3>
                <button id="closeTool" style="background: none; border: none; color: var(--text-color); font-size: 20px; cursor: pointer;">×</button>
            </div>
            <div id="toolContent" class="tool-content" style="padding: 15px;">
                <!-- Tool content will be dynamically generated -->
            </div>
        </div>
    </div>

    <!-- JavaScript for Cosmic Visualization and Audio Recording -->
    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const cosmosSphere = document.getElementById('cosmosSphere');
            const statusText = document.getElementById('statusText');
            const micButton = document.getElementById('micButton');
            const messageContainer = document.getElementById('messageContainer');
            const responseMessage = document.getElementById('responseMessage');
            
            // Create a dedicated state management object similar to audio_recorder.html
            const AppState = {
                // Recording state
                isRecording: false,
                isProcessing: false,
                pauseDetected: false,
                silenceStart: null,
                hasDetectedAudio: false,
                significantSpeechDetected: false,
                isListening: false,
                
                // Audio resources
                mediaRecorder: null,
                audioChunks: [],
                audioBlob: null,
                audioContext: null,
                analyser: null,
                source: null,
                
                // Timers and tracking
                continuousRecordingTimer: null,
                lastProcessedTime: 0,
                
                // Debug
                logPrefix: '🎤 VoiceUI:',
                
                // Methods for real-time conversation
                resetAudioState() {
                    this.isRecording = false;
                    this.isProcessing = false;
                    this.pauseDetected = false;
                    this.silenceStart = null;
                    this.hasDetectedAudio = false;
                    this.significantSpeechDetected = false;
                    this.audioChunks = [];
                    console.log(`${this.logPrefix} Audio state reset`);
                },
                
                debug() {
                    console.log(`${this.logPrefix} State: Recording: ${this.isRecording}, Processing: ${this.isProcessing}, Active: ${this.isListening}`);
                }
            };
            
            // Create cosmic particles
            createCosmicParticles();
            
            // Microphone button click handler - modified for real-time conversation
            micButton.addEventListener('click', function() {
                console.log(`${AppState.logPrefix} Mic button clicked, current state: isListening=${AppState.isListening}, isRecording=${AppState.isRecording}, isProcessing=${AppState.isProcessing}`);
                
                if (AppState.isProcessing) {
                    console.log(`${AppState.logPrefix} Ignoring mic click - currently processing`);
                    return; // Prevent multiple clicks during processing
                }
                
                if (AppState.isListening || AppState.isRecording) {
                    console.log(`${AppState.logPrefix} User clicked to stop recording`);
                    stopRecording();
                    // Change microphone icon to original icon when stopping
                    micButton.innerHTML = `
                        <svg xmlns="http://www.w3.org/2000/svg" width="28" height="28" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                            <path d="M12 1a3 3 0 0 0-3 3v8a3 3 0 0 0 6 0V4a3 3 0 0 0-3-3z"></path>
                            <path d="M19 10v2a7 7 0 0 1-14 0v-2"></path>
                            <line x1="12" y1="19" x2="12" y2="23"></line>
                            <line x1="8" y1="23" x2="16" y2="23"></line>
                        </svg>
                    `;
                } else {
                    startRecording();
                    // Change microphone icon to stop icon when recording
                    micButton.innerHTML = `
                        <svg xmlns="http://www.w3.org/2000/svg" width="28" height="28" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                            <rect x="6" y="6" width="12" height="12" rx="2" ry="2"></rect>
                        </svg>
                    `;
                    micButton.classList.add('recording');
                }
            });
            
            // Configuration settings for voice assistant
            const settings = {
                silenceThreshold: 20,  // Volume level below which is considered silence (increased)
                significantAudioThreshold: 35, // Threshold for significant speech detection (increased)
                speechDurationThreshold: 0.5, // Minimum seconds of continuous speech required
                pauseThreshold: 1.5,   // Seconds of silence before processing
                minAudioSize: 2500,    // Minimum audio blob size to process (increased)
                continuousMode: true,  // Whether to automatically resume recording
                echoCancel: true,      // Whether to use echo cancellation
                noiseSuppress: true,   // Whether to use noise suppression
                preventFeedbackLoop: true, // Prevent AI responses from being re-processed
                isSpeaking: false      // Flag to indicate when TTS is playing (prevent recording during playback)
            };
            
            // Initialize conversation history management
            let lastProcessedTranscript = '';
            let processingUserInput = false;
            let continuousSpeechDuration = 0;
            let significantSpeechTimer = null;
            let lastSignificantSpeechTime = null;
            
            // Add close conversation button functionality
            document.getElementById('closeConversation').addEventListener('click', () => {
                messageContainer.style.display = 'none';
                messageContainer.innerHTML = '';
                const responseDiv = document.createElement('div');
                responseDiv.id = 'responseMessage';
                responseDiv.style.position = 'absolute';
                responseDiv.style.left = '-9999px';
                responseDiv.style.visibility = 'hidden';
                messageContainer.appendChild(responseDiv);
            });

            // Initialize audio recording capabilities with continuous mode
            async function startRecording() {
                if (AppState.isRecording) {
                    console.log(`${AppState.logPrefix} Already recording, not starting again`);
                    return;
                }
                
                console.log(`${AppState.logPrefix} Starting recording...`);
                AppState.debug();
                
                // Reset state variables
                AppState.isRecording = true;
                AppState.isListening = true;
                AppState.pauseDetected = false;
                AppState.silenceStart = null;
                AppState.hasDetectedAudio = false;
                AppState.significantSpeechDetected = false;
                AppState.audioChunks = [];
                
                try {
                    // Request microphone access with constraints for better quality
                    const constraints = {
                        audio: {
                            echoCancellation: settings.echoCancel,
                            noiseSuppression: settings.noiseSuppress,
                            autoGainControl: true
                        }
                    };
                    
                    statusText.textContent = "Accessing microphone...";
                    const stream = await navigator.mediaDevices.getUserMedia(constraints);
                    
                    // Start animation
                    startListening();
                    
                    // Initialize audio context for visualization and volume monitoring
                    AppState.audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    AppState.analyser = AppState.audioContext.createAnalyser();
                    AppState.analyser.fftSize = 256;
                    
                    // Start media recorder with higher bitrate for better quality
                    const options = { mimeType: 'audio/webm;codecs=opus', audioBitsPerSecond: 128000 };
                    AppState.mediaRecorder = new MediaRecorder(stream, options);
                    
                    // Set up audio analysis for silence detection
                    AppState.source = AppState.audioContext.createMediaStreamSource(stream);
                    AppState.source.connect(AppState.analyser);
                    
                    // Define volume monitoring function for silence detection
                    function monitorVolume() {
                        if (!AppState.analyser || !AppState.isRecording) {
                            console.log(`${AppState.logPrefix} Cannot monitor volume - analyser or recording state invalid`);
                            return;
                        }
                        
                        // Skip volume monitoring when TTS is playing to prevent feedback
                        if (settings.isSpeaking) {
                            requestAnimationFrame(monitorVolume);
                            return;
                        }
                        
                        const bufferLength = AppState.analyser.frequencyBinCount;
                        const volumeData = new Uint8Array(bufferLength);
                        AppState.analyser.getByteFrequencyData(volumeData);
                        
                        // Calculate average volume level
                        let sum = 0;
                        for (let i = 0; i < bufferLength; i++) {
                            sum += volumeData[i];
                        }
                        const avg = sum / bufferLength;
                        
                        // Check if we've detected significant speech
                        if (avg > settings.significantAudioThreshold) {
                            // Mark when we first detected significant speech
                            if (!lastSignificantSpeechTime) {
                                lastSignificantSpeechTime = Date.now();
                                continuousSpeechDuration = 0;
                            } else {
                                // Calculate how long we've had significant speech
                                continuousSpeechDuration = (Date.now() - lastSignificantSpeechTime) / 1000;
                            }
                            
                            // Only count as speech if it's been significant for long enough
                            // This helps filter out short noise bursts and TTS audio feedback
                            if (continuousSpeechDuration >= settings.speechDurationThreshold && !AppState.significantSpeechDetected) {
                                console.log(`${AppState.logPrefix} Significant speech detected for ${continuousSpeechDuration.toFixed(2)}s - volume level: ${avg.toFixed(1)}`);
                                AppState.significantSpeechDetected = true;
                            }
                            
                            // Reset silence start when speech is detected
                            AppState.silenceStart = null;
                        } else {
                            // Reset the significant speech timer if volume drops below threshold
                            if (lastSignificantSpeechTime && avg < settings.silenceThreshold) {
                                lastSignificantSpeechTime = null;
                                continuousSpeechDuration = 0;
                            }
                        }
                        
                        // Regular audio detection for visualization
                        if (avg > settings.silenceThreshold) {
                            AppState.hasDetectedAudio = true;
                        }
                        
                        // Silence detection logic - only trigger processing if we had significant speech followed by silence
                        if (AppState.significantSpeechDetected) {
                            if (avg < settings.silenceThreshold) {
                                // Start silence timer if not already started
                                if (!AppState.silenceStart) {
                                    AppState.silenceStart = Date.now();
                                    console.log(`${AppState.logPrefix} Silence started after speech`);
                                }
                                
                                // Check if silence has lasted long enough to be a pause
                                const silenceDuration = (Date.now() - AppState.silenceStart) / 1000;
                                
                                // Only process when:
                                // 1. We've detected significant speech for minimum duration
                                // 2. Followed by silence for the pause threshold duration
                                // 3. We're not already processing
                                // 4. Enough time has passed since last processing (to avoid rapid reprocessing)
                                // 5. We're not currently playing TTS
                                if (silenceDuration > settings.pauseThreshold && 
                                    !AppState.pauseDetected && 
                                    !AppState.isProcessing &&
                                    !settings.isSpeaking &&
                                    (Date.now() - AppState.lastProcessedTime > 3000)) {
                                    
                                    console.log(`${AppState.logPrefix} Processing after ${silenceDuration.toFixed(1)}s of silence following speech`);
                                    AppState.pauseDetected = true;
                                    pauseAndProcess();
                                }
                            } else {
                                // Reset silence timer if sound detected again
                                if (AppState.silenceStart) {
                                    console.log(`${AppState.logPrefix} Silence interrupted - continuing to listen`);
                                }
                                AppState.silenceStart = null;
                            }
                        }
                        
                        // Continue monitoring as long as we're recording
                        if (AppState.isRecording) {
                            requestAnimationFrame(monitorVolume);
                        } else {
                            console.log(`${AppState.logPrefix} Volume monitoring stopped - recording ended`);
                        }
                    }
                    
                    // Start monitoring volume for silence detection
                    monitorVolume();
                    
                    // Add event listeners for audio data
                    AppState.mediaRecorder.addEventListener('dataavailable', event => {
                        if (event.data.size > 0) {
                            AppState.audioChunks.push(event.data);
                        }
                    });
                    
                    // When recording stops, process the audio
                    AppState.mediaRecorder.addEventListener('stop', () => {
                        console.log(`${AppState.logPrefix} MediaRecorder stopped, chunks: ${AppState.audioChunks.length}`);
                        if (AppState.audioChunks.length > 0) {
                            AppState.audioBlob = new Blob(AppState.audioChunks, { type: 'audio/webm;codecs=opus' });
                            console.log(`${AppState.logPrefix} Audio blob created, size: ${AppState.audioBlob.size}`);
                            if (!AppState.isProcessing) {
                                processAudio();
                            }
                        }
                    });
                    
                    // Start recording in chunks of 100ms
                    AppState.mediaRecorder.start(100);
                    statusText.textContent = "Listening...";
                    
                    // Start continuous recording timer if enabled
                    if (settings.continuousMode) {
                        startContinuousRecordingTimer();
                    }
                    
                    // Setup visualization animation
                    function animate() {
                        if (!AppState.isListening) return;
                        
                        const bufferLength = AppState.analyser.frequencyBinCount;
                        const dataArray = new Uint8Array(bufferLength);
                        AppState.analyser.getByteFrequencyData(dataArray);
                        
                        // Calculate average volume
                        let sum = 0;
                        for (let i = 0; i < bufferLength; i++) {
                            sum += dataArray[i];
                        }
                        const average = sum / bufferLength;
                        
                        // Scale particles based on volume
                        const particles = document.querySelectorAll('.particle');
                        const scale = 1 + (average / 256) * 0.5; // Scale between 1 and 1.5
                        
                        // Make cosmos sphere pulsate based on audio level
                        const pulseScale = 1 + (average / 256) * 0.1; // Subtle pulse effect
                        cosmosSphere.style.transform = `scale(${pulseScale})`;
                        
                        particles.forEach(particle => {
                            particle.style.transform = `scale(${scale})`;
                        });
                        
                        requestAnimationFrame(animate);
                    }
                    
                    animate();
                    
                } catch (err) {
                    console.error(`${AppState.logPrefix} Error accessing microphone:`, err);
                    alert('Error accessing microphone. Please ensure your microphone is connected and permissions are granted.');
                    
                    // Reset state on error
                    AppState.isRecording = false;
                    AppState.isListening = false;
                }
            }
            
            // Function to start continuous recording timer
            function startContinuousRecordingTimer() {
                // Clear any existing timer
                if (AppState.continuousRecordingTimer) {
                    clearInterval(AppState.continuousRecordingTimer);
                    AppState.continuousRecordingTimer = null;
                }
                
                console.log(`${AppState.logPrefix} Continuous listening mode active - will process on speech followed by silence`);
            }
            
            // Pause recording and process current audio
            function pauseAndProcess() {
                console.log(`${AppState.logPrefix} Pausing to process audio`);
                
                if (!AppState.isRecording || AppState.isProcessing) {
                    console.log(`${AppState.logPrefix} Cannot pause - not recording or already processing`);
                    return;
                }
                
                // Stop the current recorder to get the data
                if (AppState.mediaRecorder && AppState.mediaRecorder.state !== 'inactive') {
                    AppState.mediaRecorder.stop();
                }
                
                statusText.textContent = "Processing your message...";
                
                // Update state
                AppState.isRecording = false;
                
                // Store the callback on the window object so it can be accessed from anywhere
                window.resumeRecordingCallback = resumeRecording;
            }
            
            // Resume recording function for continuous conversation
            async function resumeRecording() {
                console.log(`${AppState.logPrefix} Resuming recording callback triggered`);
                
                // Check if still in listening mode
                if (AppState.isListening) {
                    console.log(`${AppState.logPrefix} Resuming recording - still active`);
                    
                    try {
                        // Reset AppState for a fresh start with the new recording session
                        AppState.isRecording = false;
                        AppState.isProcessing = false;
                        AppState.significantSpeechDetected = false;
                        AppState.pauseDetected = false;
                        AppState.silenceStart = null;
                        AppState.audioChunks = [];
                        
                        // Request a fresh microphone stream
                        const constraints = {
                            audio: {
                                echoCancellation: settings.echoCancel,
                                noiseSuppression: settings.noiseSuppress,
                                autoGainControl: true
                            }
                        };
                        
                        console.log(`${AppState.logPrefix} Requesting fresh microphone stream`);
                        const stream = await navigator.mediaDevices.getUserMedia(constraints);
                        
                        // Start a new recorder with the fresh stream
                        const options = { mimeType: 'audio/webm;codecs=opus', audioBitsPerSecond: 128000 };
                        AppState.mediaRecorder = new MediaRecorder(stream, options);
                        
                        // Set up event handlers again
                        AppState.mediaRecorder.addEventListener('dataavailable', event => {
                            if (event.data.size > 0) {
                                AppState.audioChunks.push(event.data);
                            }
                        });
                        
                        AppState.mediaRecorder.addEventListener('stop', () => {
                            if (AppState.audioChunks.length > 0) {
                                AppState.audioBlob = new Blob(AppState.audioChunks, { type: 'audio/webm;codecs=opus' });
                                if (!AppState.isProcessing) {
                                    processAudio();
                                }
                            }
                        });
                        
                        // Set up audio analysis again with the fresh stream
                        if (AppState.audioContext && AppState.analyser) {
                            // Disconnect previous source if exists
                            if (AppState.source) {
                                AppState.source.disconnect();
                            }
                            
                            AppState.source = AppState.audioContext.createMediaStreamSource(stream);
                            AppState.source.connect(AppState.analyser);
                            
                            // Start recording first, then visualization
                            AppState.mediaRecorder.start(100);
                            AppState.isRecording = true;
                            
                            // Start monitoring volume with the fresh stream
                            setTimeout(() => {
                                console.log(`${AppState.logPrefix} Starting volume monitoring`);
                                monitorVolume();
                            }, 100);
                        } else {
                            throw new Error("Audio context or analyser not properly initialized");
                        }
                        
                        statusText.textContent = "Listening...";
                        console.log(`${AppState.logPrefix} Successfully restarted recording with fresh stream`);
                        
                    } catch (error) {
                        console.error(`${AppState.logPrefix} Error resuming recording:`, error);
                        statusText.textContent = "Error resuming: " + error.message;
                    }
                } else {
                    console.log(`${AppState.logPrefix} Not resuming recording - conversation has ended`);
                }
            };
            
            // Stop recording function
            function stopRecording() {
                if (!AppState.isRecording) {
                    console.log(`${AppState.logPrefix} Cannot stop recording - not currently recording`);
                    return;
                }
                
                console.log(`${AppState.logPrefix} Stopping recording...`);
                
                AppState.isRecording = false;
                AppState.isListening = false;
                
                if (AppState.mediaRecorder && AppState.mediaRecorder.state !== 'inactive') {
                    AppState.mediaRecorder.stop();
                }
                
                // Clean up continuous recording timer if active
                if (settings.continuousMode && AppState.continuousRecordingTimer) {
                    clearTimeout(AppState.continuousRecordingTimer);
                    AppState.continuousRecordingTimer = null;
                }
                
                // Ensure UI shows recording has stopped
                statusText.textContent = "Recording stopped";
                stopListening();
                
                // Reset all state flags
                window.resumeRecordingCallback = null;
                AppState.significantSpeechDetected = false;
                AppState.pauseDetected = false;
                AppState.silenceStart = null;
                lastSignificantSpeechTime = null;
                continuousSpeechDuration = 0;
            }
            
            async function processAudio() {
                try {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    const formData = new FormData();
                    formData.append('audio', audioBlob);
                    
                    statusText.textContent = 'Processing...';
                    statusText.classList.add('active');
                    
                    // Send to backend for processing
                    const response = await fetch('/api/stt', {
                        method: 'POST',
                        body: formData
                    });
                    
                    const data = await response.json();

                    console.log('Backend response from stt:', data);
                    
                    if (data.success) {
                        // Process the transcript
                        const transcript = data.transcript;
                        console.log('Transcript:', transcript);
                        
                        // Show user message
                        const userBubble = document.createElement('div');
                        userBubble.className = 'user-bubble';
                        userBubble.textContent = transcript;
                        messageContainer.appendChild(userBubble);
                        messageContainer.style.display = 'block';
                        
                        statusText.textContent = 'Thinking...';
                        
                        // Now get AI response for the transcript
                        const aiResponse = await fetch('/api/tts', {
                            method: 'POST',
                            headers: {
                                'Content-Type': 'application/json'
                            },
                            body: JSON.stringify({ text: transcript })
                        });
                        
                        const aiData = await aiResponse.json();
                        
                        if (aiData.success) {
                            // Display AI response
                            simulateResponse(aiData.response);
                            
                            // Convert to speech
                            speakResponse(aiData.response);
                        } else {
                            simulateResponse("I'm sorry, I couldn't process your request. Please try again.");
                        }
                    } else {
                        simulateResponse("I couldn't hear you clearly. Could you please try again?");
                    }
                } catch (err) {
                    console.error('Error processing audio:', err);
                    simulateResponse("There was an error processing your audio. Please try again.");
                } finally {
                    isProcessing = false;
                    statusText.classList.remove('active');
                }
            }
            
            async function speakResponse(text) {
                try {
                    // Set the speaking flag to true to prevent the system from listening to itself
                    settings.isSpeaking = true;
                    console.log(`${AppState.logPrefix} TTS starting - blocking mic input to prevent feedback`);
                    
                    // Fetch TTS audio
                    const response = await fetch('/api/tts', {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json'
                        },
                        body: JSON.stringify({ text: text })
                    });
                    
                    if (!response.ok) {
                        throw new Error('Failed to convert text to speech');
                    }
                    
                    const blob = await response.blob();
                    const audioURL = URL.createObjectURL(blob);
                    const audio = new Audio(audioURL);
                    
                    // Set up event handlers
                    audio.onended = () => {
                        console.log(`${AppState.logPrefix} TTS playback complete - unblocking mic input`);
                        URL.revokeObjectURL(audioURL);
                        settings.isSpeaking = false;
                        // Reset speech detection variables to prevent false triggers
                        AppState.significantSpeechDetected = false;
                    };
                    
                    // Add safety timeout in case onended doesn't fire
                    const safetyTimeout = setTimeout(() => {
                        if (settings.isSpeaking) {
                            console.log(`${AppState.logPrefix} Safety timeout triggered for TTS`);
                            URL.revokeObjectURL(audioURL);
                            settings.isSpeaking = false;
                        }
                    }, 30000); // 30 second maximum for any TTS playback
                    
                    await audio.play();
                } catch (error) {
                    console.error('TTS Error:', error);
                    // Make sure to reset the speaking flag in case of error
                    settings.isSpeaking = false;
                }
            }
            
            // Tool Functions for Sidebar
            function showTool(title, content) {
                const toolSidebar = document.getElementById('toolSidebar');
                const toolTitle = document.getElementById('toolTitle');
                const toolContent = document.getElementById('toolContent');
                
                // Set tool content
                toolTitle.textContent = title;
                toolContent.innerHTML = content;
                
                // Show sidebar
                toolSidebar.style.width = 'var(--sidebar-width)';
                
                // Update CSS variables to adjust the main container
                document.documentElement.style.setProperty('--main-container-width', 'calc(100% - 175px)');
                document.documentElement.style.setProperty('--main-container-transform', '-75px');
            }
            
            function hideTool() {
                const toolSidebar = document.getElementById('toolSidebar');
                toolSidebar.style.width = '0';
                
                // Reset main container position using CSS variables
                document.documentElement.style.setProperty('--main-container-width', '100%');
                document.documentElement.style.setProperty('--main-container-transform', '0');
            }
            
            // Close tool button event listener
            document.getElementById('closeTool').addEventListener('click', () => {
                hideTool();
            });
            
            // Tool detection system - comprehensive version from audio_recorder.html
            function detectToolIntent(transcript) {
                const text = transcript.toLowerCase();
                console.log(`${AppState.logPrefix} Analyzing intent for: "${text}"`);

                // Email writing/sending detection
                if (text.includes("write an email") ||
                    text.includes("send an email") ||
                    text.includes("compose an email") ||
                    ((text.includes("email") || text.includes("mail")) &&
                        (text.includes("to ") || text.includes("write") || text.includes("send") || text.includes("compose")))) {

                    // Try to extract recipient
                    let recipient = "recipient";
                    let subject = "Meeting Follow-up";

                    // Extract recipient with various patterns
                    const recipientPatterns = [
                        /(?:email|mail|send|write)\s+to\s+([a-z0-9\s]+)(?:about|with|saying|regarding)?/i,
                        /(?:email|mail|send|write)\s+([a-z0-9\s]+)(?:\s+an email|\s+a message)?/i,
                        /(?:compose|create|draft)(?:\s+an email|\s+a message)?\s+(?:to|for)\s+([a-z0-9\s]+)/i
                    ];

                    for (const pattern of recipientPatterns) {
                        const match = text.match(pattern);
                        if (match && match[1]) {
                            recipient = match[1].trim();
                            break;
                        }
                    }

                    // Extract subject if mentioned
                    const subjectMatch = text.match(/about\s+["']?([^"']+)["']?/i) ||
                        text.match(/(?:with|regarding)\s+(?:the\s+)?(?:subject|title)\s+["']?([^"']+)["']?/i);

                    if (subjectMatch && subjectMatch[1]) {
                        subject = subjectMatch[1].trim();
                    }

                    console.log(`${AppState.logPrefix} Detected email intent with recipient: ${recipient}, subject: ${subject}`);

                    return {
                        tool: "email",
                        action: "compose",
                        params: { recipient, subject }
                    };
                }

                // Email summary detection
                if ((text.includes("summarize") || text.includes("summary") || text.includes("check")) &&
                    (text.includes("email") || text.includes("inbox") || text.includes("messages"))) {

                    // Try to extract count
                    let count = 3; // Default
                    const countMatch = text.match(/(\d+)\s+(?:emails|messages|recent)/i) ||
                        text.match(/(?:emails|messages|recent)\s+(\d+)/i);

                    if (countMatch && countMatch[1]) {
                        count = parseInt(countMatch[1], 10);
                    }

                    console.log(`${AppState.logPrefix} Detected email summary intent for ${count} emails`);

                    return {
                        tool: "email",
                        action: "summarize",
                        params: { count }
                    };
                }

                // Calendar check detection
                if (text.includes("calendar") &&
                    (text.includes("check") || text.includes("look") || text.includes("view") ||
                        text.includes("availability") || text.includes("free") || text.includes("busy") ||
                        text.includes("schedule") || text.includes("appointments") ||
                        text.includes("when am i"))) {

                    // Try to extract date
                    let date = "today";
                    const datePatterns = [
                        /(?:calendar|schedule|availability)(?:\s+for|\s+on)?\s+([a-z0-9\s,]+)/i,
                        /(?:free|busy|available)(?:\s+on|\s+during)?\s+([a-z0-9\s,]+)/i,
                        /what(?:'s|\s+is)(?:\s+my)?\s+(?:schedule|calendar)(?:\s+for|\s+on)?\s+([a-z0-9\s,]+)/i
                    ];

                    for (const pattern of datePatterns) {
                        const match = text.match(pattern);
                        if (match && match[1]) {
                            date = match[1].trim();
                            break;
                        }
                    }

                    console.log(`${AppState.logPrefix} Detected calendar check intent for date: ${date}`);

                    return {
                        tool: "calendar",
                        action: "check",
                        params: { date }
                    };
                }

                // Calendar add event detection
                if ((text.includes("add") || text.includes("create") || text.includes("schedule") || text.includes("set up")) &&
                    (text.includes("event") || text.includes("meeting") || text.includes("appointment") || text.includes("reminder")) &&
                    (text.includes("calendar") || text.includes("schedule"))) {

                    // Extract event details
                    let title = "New Event";
                    let date = "today";
                    let time = "12:00";

                    // Extract title
                    const titlePatterns = [
                        /(?:add|create|schedule|set up)(?:\s+a|\s+an)?\s+(?:event|meeting|appointment|reminder)(?:\s+called|\s+titled|\s+named)?\s+["']?([^"']+)["']?/i,
                        /(?:add|create|schedule|set up)(?:\s+a|\s+an)?\s+["']?([^"']+)["']?(?:\s+event|\s+meeting|\s+appointment|\s+reminder)/i
                    ];

                    for (const pattern of titlePatterns) {
                        const match = text.match(pattern);
                        if (match && match[1]) {
                            title = match[1].trim();
                            break;
                        }
                    }

                    // Extract date and time
                    const dateTimePatterns = [
                        /(?:on|for)\s+([a-z0-9\s,]+)(?:\s+at)?\s+(?:at\s+)?(\d{1,2}(?::\d{2})?\s*(?:am|pm)?)/i,
                        /(?:at|on)\s+(\d{1,2}(?::\d{2})?\s*(?:am|pm)?)(?:\s+on)?\s+([a-z0-9\s,]+)/i
                    ];

                    for (const pattern of dateTimePatterns) {
                        const match = text.match(pattern);
                        if (match) {
                            if (match[1] && match[2]) {
                                // Check which is date and which is time
                                if (match[1].match(/\d{1,2}(?::\d{2})?\s*(?:am|pm)?/i)) {
                                    time = match[1].trim();
                                    date = match[2].trim();
                                } else {
                                    date = match[1].trim();
                                    time = match[2].trim();
                                }
                                break;
                            }
                        }
                    }

                    console.log(`${AppState.logPrefix} Detected calendar add intent - Title: ${title}, Date: ${date}, Time: ${time}`);

                    return {
                        tool: "calendar",
                        action: "add",
                        params: { title, date, time }
                    };
                }

                // No tool intent detected
                console.log(`${AppState.logPrefix} No tool intent detected, treating as conversation`);
                return null;
            }
            
            // Handle tool intent based on detected parameters
            function handleToolIntent(toolIntent, transcript) {
                if (!toolIntent) return false;
                
                console.log(`${AppState.logPrefix} Handling tool intent:`, toolIntent);
                
                if (toolIntent.tool === 'email') {
                    if (toolIntent.action === 'compose') {
                        handleEmailCompose(toolIntent.params.recipient, toolIntent.params.subject, transcript);
                        return true;
                    } else if (toolIntent.action === 'summarize') {
                        handleEmailSummarize(toolIntent.params.count, transcript);
                        return true;
                    }
                } else if (toolIntent.tool === 'calendar') {
                    if (toolIntent.action === 'check') {
                        handleCalendarCheck(toolIntent.params.date, transcript);
                        return true;
                    } else if (toolIntent.action === 'add') {
                        handleCalendarAdd(toolIntent.params.title, toolIntent.params.date, toolIntent.params.time, transcript);
                        return true;
                    }
                }
                
                return false;
            }
            
            // Handle email composition
            function handleEmailCompose(recipient, subject, transcript) {
                const emailContent = `
                    <div class="email-form">
                        <div class="email-field">
                            <label>To:</label>
                            <input type="text" id="emailTo" value="${recipient}">
                        </div>
                        <div class="email-field">
                            <label>Subject:</label>
                            <input type="text" id="emailSubject" value="${subject}" placeholder="Email subject">
                        </div>
                        <div class="email-field">
                            <label>Message:</label>
                            <textarea id="emailBody" rows="10" placeholder="Compose your message here..."></textarea>
                        </div>
                        <div class="tool-buttons">
                            <button id="cancelEmail" class="tool-button secondary">Cancel</button>
                            <button id="sendEmail" class="tool-button primary">Send Email</button>
                        </div>
                    </div>
                `;
                
                showTool('Compose Email', emailContent);
                
                // Add event listeners for the buttons
                setTimeout(() => {
                    document.getElementById('cancelEmail')?.addEventListener('click', hideTool);
                    document.getElementById('sendEmail')?.addEventListener('click', () => {
                        simulateResponse("Email sent to " + document.getElementById('emailTo').value + "!");
                        hideTool();
                    });
                }, 100);
            }
            
            // Handle email summarize
            function handleEmailSummarize(count, transcript) {
                const emailContent = `
                    <div class="email-summary">
                        <h3>Email Summary</h3>
                        <div class="email-list">
                            <div class="email-item">
                                <div class="email-header">
                                    <div class="email-sender">John Smith</div>
                                    <div class="email-time">10:30 AM</div>
                                </div>
                                <div class="email-subject">Project Update</div>
                                <div class="email-preview">Here's the latest on the DelightMate project...</div>
                            </div>
                            <div class="email-item">
                                <div class="email-header">
                                    <div class="email-sender">Sarah Johnson</div>
                                    <div class="email-time">Yesterday</div>
                                </div>
                                <div class="email-subject">Meeting Notes</div>
                                <div class="email-preview">Attached are the notes from our meeting...</div>
                            </div>
                            <div class="email-item">
                                <div class="email-header">
                                    <div class="email-sender">Tech Team</div>
                                    <div class="email-time">Feb 10</div>
                                </div>
                                <div class="email-subject">New Feature Announcement</div>
                                <div class="email-preview">We're excited to announce the launch of...</div>
                            </div>
                        </div>
                        <div class="tool-buttons">
                            <button id="closeEmailSummary" class="tool-button primary">Close</button>
                        </div>
                    </div>
                `;
                
                showTool('Email Summary', emailContent);
                
                // Add event listener for the close button
                setTimeout(() => {
                    document.getElementById('closeEmailSummary')?.addEventListener('click', hideTool);
                }, 100);
            }
            
            // Handle calendar check
            function handleCalendarCheck(date, transcript) {
                const calendarContent = `
                    <div class="calendar-view">
                        <h3>Calendar for ${date}</h3>
                        <div class="calendar-day">
                            <div class="calendar-event">
                                <div class="event-time">9:00 AM - 10:00 AM</div>
                                <div class="event-title">Team Stand-up</div>
                            </div>
                            <div class="calendar-event">
                                <div class="event-time">11:30 AM - 12:30 PM</div>
                                <div class="event-title">Client Meeting</div>
                            </div>
                            <div class="calendar-event">
                                <div class="event-time">2:00 PM - 3:30 PM</div>
                                <div class="event-title">Design Review</div>
                            </div>
                        </div>
                        <div class="tool-buttons">
                            <button id="closeCalendarCheck" class="tool-button primary">Close</button>
                        </div>
                    </div>
                `;
                
                showTool(`Calendar: ${date}`, calendarContent);
                
                // Add event listener for the close button
                setTimeout(() => {
                    document.getElementById('closeCalendarCheck')?.addEventListener('click', hideTool);
                }, 100);
            }
            
            // Handle calendar add event
            function handleCalendarAdd(title, date, time, transcript) {
                const calendarContent = `
                    <div class="calendar-form">
                        <div class="calendar-field">
                            <label>Event:</label>
                            <input type="text" id="eventTitle" value="${title}" placeholder="Event title">
                        </div>
                        <div class="calendar-field">
                            <label>Date:</label>
                            <input type="date" id="eventDate" value="${date === 'today' ? new Date().toISOString().split('T')[0] : date}">
                        </div>
                        <div class="calendar-field">
                            <label>Time:</label>
                            <input type="time" id="eventTime" value="${time.includes(':') ? time : time + ':00'}">
                        </div>
                        <div class="calendar-field">
                            <label>Attendees:</label>
                            <input type="text" id="eventAttendees" placeholder="Add attendees (optional)">
                        </div>
                        <div class="tool-buttons">
                            <button id="cancelCalendarAdd" class="tool-button secondary">Cancel</button>
                            <button id="addCalendarEvent" class="tool-button primary">Add to Calendar</button>
                        </div>
                    </div>
                `;
                
                showTool('Add Calendar Event', calendarContent);
                
                // Add event listeners for the buttons
                setTimeout(() => {
                    document.getElementById('cancelCalendarAdd')?.addEventListener('click', hideTool);
                    document.getElementById('addCalendarEvent')?.addEventListener('click', () => {
                        const eventTitle = document.getElementById('eventTitle').value;
                        simulateResponse(`Added "${eventTitle}" to your calendar!`);
                        hideTool();
                    });
                }, 100);
            }
            
            // Add custom styles for tool UI components
            const styleElement = document.createElement('style');
            styleElement.textContent = `
                .email-form, .calendar-form, .calendar-view, .email-summary {
                    display: flex;
                    flex-direction: column;
                    gap: 15px;
                    color: var(--text-color);
                }
                
                .email-field, .calendar-field {
                    display: flex;
                    flex-direction: column;
                    gap: 8px;
                }
                
                .email-field label, .calendar-field label {
                    font-weight: bold;
                    font-size: 0.9rem;
                }
                
                .email-field input, .email-field textarea, .calendar-field input {
                    padding: 10px;
                    border: 1px solid rgba(125, 125, 125, 0.5);
                    border-radius: 6px;
                    background-color: rgba(255, 255, 255, 0.05);
                    color: var(--text-color);
                }
                
                .tool-buttons {
                    display: flex;
                    justify-content: flex-end;
                    gap: 10px;
                    margin-top: 15px;
                }
                
                .tool-button {
                    padding: 8px 16px;
                    border-radius: 6px;
                    cursor: pointer;
                    font-weight: bold;
                }
                
                .tool-button.primary {
                    background: #50b3a2;
                    color: white;
                    border: none;
                }
                
                .tool-button.secondary {
                    background: rgba(125, 125, 125, 0.2);
                    color: var(--text-color);
                    border: 1px solid rgba(125, 125, 125, 0.5);
                }
                
                .email-summary, .calendar-view {
                    padding: 10px;
                }
                
                .email-item, .calendar-event {
                    border: 1px solid rgba(125, 125, 125, 0.3);
                    border-radius: 8px;
                    padding: 12px;
                    margin-bottom: 10px;
                    background-color: rgba(255, 255, 255, 0.05);
                }
                
                .email-header, .event-time {
                    display: flex;
                    justify-content: space-between;
                    margin-bottom: 5px;
                    font-weight: bold;
                }
                
                .email-subject, .event-title {
                    font-weight: bold;
                    margin-bottom: 5px;
                }
            `;
            document.head.appendChild(styleElement);
            
            // Create cosmic particles in the sphere
            function createCosmicParticles() {
                const colors = ['white', 'blue', 'cyan', 'purple', 'pink'];
                const totalParticles = 200;
                const sphereRadius = 180; // Radius of the cosmic sphere
                
                cosmosSphere.innerHTML = ''; // Clear existing particles
                
                for (let i = 0; i < totalParticles; i++) {
                    const particle = document.createElement('div');
                    particle.className = `particle ${colors[Math.floor(Math.random() * colors.length)]}`;
                    
                    // Random size between 2-6px
                    const size = Math.random() * 4 + 2;
                    particle.style.width = `${size}px`;
                    particle.style.height = `${size}px`;
                    
                    // Position randomly within the sphere (spherical coordinates)
                    const theta = Math.random() * Math.PI * 2; // Horizontal angle
                    const phi = Math.acos(2 * Math.random() - 1); // Vertical angle
                    const radius = Math.random() * sphereRadius; // Distance from center
                    
                    const x = radius * Math.sin(phi) * Math.cos(theta);
                    const y = radius * Math.sin(phi) * Math.sin(theta);
                    const z = radius * Math.cos(phi);
                    
                    // Calculate opacity based on distance from center (more transparency at edges)
                    const opacity = 0.1 + (1 - (radius / sphereRadius)) * 0.9;
                    
                    // Set animation delay as a CSS variable
                    const delay = Math.random() * 2;
                    particle.style.setProperty('--particle-delay', delay);
                    
                    // Apply styles
                    particle.style.left = `calc(50% + ${x}px)`;
                    particle.style.top = `calc(50% + ${y}px)`;
                    particle.style.opacity = opacity;
                    particle.style.transform = `translateZ(${z}px)`;
                    
                    // Add subtle movement animation
                    const animDuration = 20 + Math.random() * 80;
                    const animDelay = Math.random() * -animDuration;
                    
                    // Use multiple animations for more interesting movement
                    particle.style.animation = `
                        rotate ${animDuration}s linear ${animDelay}s infinite,
                        float ${10 + Math.random() * 10}s ease-in-out ${Math.random() * -10}s infinite
                    `;
                    
                    cosmosSphere.appendChild(particle);
                }
            }
            
            // Start listening animation
            function startListening() {
                isListening = true;
                document.body.classList.add('listening');
                statusText.classList.add('active');
                statusText.textContent = 'Listening...';
                cosmosSphere.classList.add('pulsate');
                messageContainer.style.display = 'none';
                
                // Make particles bulge with microphone input (real-time audio will handle this)
                const particles = document.querySelectorAll('.particle');
                particles.forEach(particle => {
                    // Add random delay for each particle to create a wave effect
                    const randomDelay = Math.random() * 0.5;
                    particle.style.setProperty('--particle-delay', randomDelay);
                });
            }
            
            // Stop listening animation
            function stopListening() {
                isListening = false;
                document.body.classList.remove('listening');
                statusText.classList.remove('active');
                cosmosSphere.classList.remove('pulsate');
                cosmosSphere.style.transform = '';
                
                // Show welcome message after response is displayed
                setTimeout(() => {
                    const welcomeMessage = document.getElementById('welcomeMessage');
                    if (welcomeMessage && !messageContainer.style.display || messageContainer.style.display === 'none') {
                        welcomeMessage.style.opacity = '0.95';
                        welcomeMessage.style.transform = 'translateY(-100px)';
                    }
                }, 1000);
                
                // Reset particles
                const particles = document.querySelectorAll('.particle');
                particles.forEach(particle => {
                    particle.style.transform = '';
                });
            }
            
            // Display AI response with animation
            // Add message to conversation log (user or AI)
            function addToConversationLog(message, sender) {
                // Make sure the message container is visible
                messageContainer.style.display = 'block';
                
                // Create a new message bubble with proper alignment
                const messageBubble = document.createElement('div');
                if (sender === 'user') {
                    messageBubble.className = 'message-bubble user-message';
                    messageBubble.style.cssText = 'background-color: #e3f2fd; color: #0d47a1; border-radius: 18px; padding: 12px; margin: 8px 0; border-bottom-right-radius: 4px; margin-left: auto; max-width: 80%; word-wrap: break-word; box-shadow: 0 1px 2px rgba(0, 0, 0, 0.1); animation: message-appear 0.3s ease-out;';
                } else {
                    messageBubble.className = 'message-bubble ai-message';
                    messageBubble.style.cssText = 'background-color: #f1f1f1; color: #333; border-radius: 18px; padding: 12px; margin: 8px 0; border-bottom-left-radius: 4px; margin-right: auto; max-width: 80%; word-wrap: break-word; box-shadow: 0 1px 2px rgba(0, 0, 0, 0.1); animation: message-appear 0.3s ease-out;';
                }
                
                messageContainer.appendChild(messageBubble);
                
                // Animate text appearing word by word
                const words = message.split(' ');
                if (sender === 'ai') {
                    responseMessage.textContent = ''; // Clear existing text for screen readers
                }
                
                let wordIndex = 0;
                const wordInterval = setInterval(() => {
                    if (wordIndex < words.length) {
                        messageBubble.textContent += (wordIndex === 0 ? '' : ' ') + words[wordIndex];
                        if (sender === 'ai') {
                            responseMessage.textContent = messageBubble.textContent; // For screen readers
                        }
                        wordIndex++;
                    } else {
                        clearInterval(wordInterval);
                    }
                }, 50);
                
                // Scroll to the bottom of the container
                messageContainer.scrollTop = messageContainer.scrollHeight;
            }

            // Display AI response (wrapper for addToConversationLog)
            function simulateResponse(text) {
                addToConversationLog(text, 'ai');
            }
        });
    </script>

    <!-- Footer -->
    <footer class="py-4 text-center text-blue-800 mt-auto">
        <p class="text-sm">&copy; 2025 DelightMate - Your Intelligent Assistant</p>
    </footer>

</body>
</html>